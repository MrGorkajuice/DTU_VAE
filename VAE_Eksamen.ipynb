{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Deep Learning project\n",
    "This notebook contains the Python code for the final project by the group \"Uffe & Axel\" in the 02456 Deep Learning course autumn 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEBI-teSY67-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torchvision.datasets import MNIST\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import Bernoulli\n",
    "from typing import Dict, Any\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler\n",
    "from collections import defaultdict\n",
    "from IPython.display import Image, display, clear_output\n",
    "import statistics\n",
    "import math\n",
    "import os.path\n",
    "import socket\n",
    "from torch.distributions import Categorical\n",
    "# Static random seed\n",
    "np.random.seed(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LAMBDAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert data to Tensor, because the DataLoader iterator refuses to work with PIL image objects.\n",
    "pil2tensor = lambda x: ToTensor()(x).squeeze()   # ToTensor return (64,1,28,28), the squeeze() call removes the 1 dimension\n",
    "\n",
    "# Binarize method for binarized dataset\n",
    "binarize = lambda x: torch.bernoulli(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwTMdXXreBbl"
   },
   "outputs": [],
   "source": [
    "mnist_train_data = MNIST(\"./temp/\", transform=pil2tensor, download=True, train=True)\n",
    "mnist_test_data = MNIST(\"./temp/\", transform=pil2tensor, download=True, train=False)\n",
    "\n",
    "binarized_mnist_train_data = MNIST(\"./temp/\",\n",
    "                                   download=True,\n",
    "                                   train=True,\n",
    "                                   transform=transforms.Compose([pil2tensor,\n",
    "                                                                 binarize]))\n",
    "binarized_mnist_test_data = MNIST(\"./temp/\",\n",
    "                                  download=True,\n",
    "                                  train=False,\n",
    "                                  transform=transforms.Compose([pil2tensor,\n",
    "                                                                binarize]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATALOADERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_indices(dataset, total_labels):\n",
    "    # return random list of indicies into 'dataset' that point to an equal amount of each label 0 to 9\n",
    "    idx_list = []\n",
    "    for target in range(10):\n",
    "        idx_list += random.sample(list(np.where([dataset.targets.numpy() == target])[1]), k=int(total_labels/10))\n",
    "    return idx_list\n",
    "for cnt, idx in enumerate(label_indices(binarized_mnist_train_data, 10)):\n",
    "    assert cnt == binarized_mnist_train_data[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_setup(labelled_size = 10000,\n",
    "                 unlabelled_size = None,    # None: 50k - lbl_size\n",
    "                 validation_size = 10000,\n",
    "                 test_size = None,          # None: use all 10k\n",
    "                 batch_size = 64):\n",
    "    '''Setup all data loaders, providing labelled, unlabelled, validation & test samples'''\n",
    "    global binarized_mnist_train_loader_labelled\n",
    "    global binarized_mnist_train_loader_unlabelled\n",
    "    global binarized_mnist_train_loader_validation\n",
    "    global binarized_mnist_test_loader\n",
    "    if unlabelled_size == None:\n",
    "        unlabelled_size = 50000 - labelled_size\n",
    "    indices_train = np.arange(len(binarized_mnist_train_data)) # 60000\n",
    "\n",
    "    labelled_idx = label_indices(binarized_mnist_train_data, labelled_size)\n",
    "    unlabelled_idx = random.sample(list(np.setdiff1d(indices_train, labelled_idx)\n",
    "                                       ), k=unlabelled_size)\n",
    "    validation_idx = random.sample(list(np.setdiff1d(indices_train, \n",
    "                                                     np.concatenate((labelled_idx,unlabelled_idx)))\n",
    "                                       ), k=validation_size)\n",
    "\n",
    "    # Last, generate the dataloaders\n",
    "    #\n",
    "    # There is no need to add 'shuffle=True' to DataLoader. Test show that each re-run will shuffle the data\n",
    "    # for the next epoch.\n",
    "    binarized_mnist_train_loader_labelled = DataLoader(binarized_mnist_train_data, \n",
    "                                                       batch_size = batch_size,\n",
    "                                                       sampler = SubsetRandomSampler(labelled_idx))\n",
    "    if unlabelled_size == 0:\n",
    "        # The M2 trainer skips unlabelled training if train_loader is 'None'\n",
    "        binarized_mnist_train_loader_unlabelled = None\n",
    "    else:\n",
    "        binarized_mnist_train_loader_unlabelled = DataLoader(binarized_mnist_train_data, \n",
    "                                                             batch_size = batch_size, \n",
    "                                                             sampler = SubsetRandomSampler(unlabelled_idx))\n",
    "    binarized_mnist_train_loader_validation = DataLoader(binarized_mnist_train_data, \n",
    "                                                         batch_size = batch_size, \n",
    "                                                         sampler = SubsetRandomSampler(validation_idx))\n",
    "    if test_size == None:\n",
    "        test_size = len(binarized_mnist_test_data)  # 10000\n",
    "    indices_test = np.arange(test_size)\n",
    "    binarized_mnist_test_loader = DataLoader(binarized_mnist_test_data, \n",
    "                                             batch_size = 64, \n",
    "                                             sampler = SubsetRandomSampler(indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_setup(labelled_size=10, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: Can we rely on DataLoader to visit every contained sample over the course \n",
    "# of one epoch when using SubsetRandomSampler?\n",
    "\n",
    "# ANSWER: yes. Here we check that restarting data loader will gives same pictures in new order, \n",
    "# and also that all pictures in the set are visited. Run this cell a couple of times to verify.\n",
    "for images,labels in binarized_mnist_train_loader_labelled:\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(6, 3), squeeze=False)\n",
    "    for i,ax in enumerate(axs.flat):\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "        ax.set_title(\"%s\" % (labels[i].item()))\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_setup(labelled_size=10000, \n",
    "             unlabelled_size=40000, \n",
    "             validation_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-binarized dataloader\n",
    "indices_train = list(range(len(mnist_train_data))) # 60000\n",
    "mnist_train_loader = DataLoader(mnist_train_data, \n",
    "                                batch_size = 64, \n",
    "                                sampler = SubsetRandomSampler(indices_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REPARAMETERIZED DIAGONAL GUASSIAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "370tki2E3CBG"
   },
   "outputs": [],
   "source": [
    "# Implement reparameterized diagonal gaussian\n",
    "#from torch.distributions import Distribution\n",
    "\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    def __init__(self, mu: Tensor, log_sigma: Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        return self.mu + self.sigma*self.sample_epsilon()\n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        from torch.distributions import Normal \n",
    "        return  Normal(loc=self.mu, scale=self.sigma).log_prob(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NETWORK CONSTRUCTOR HELPER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FF_NetworkConstructor(layers: [],\n",
    "                          pre_batchnorm: bool,\n",
    "                          hidden_batchnorm: bool,\n",
    "                          hidden_activation,\n",
    "                          dropout_prob: float,\n",
    "                          final_activation) -> nn.Sequential:\n",
    "    constructor = []\n",
    "    if pre_batchnorm:\n",
    "        constructor.append(nn.BatchNorm1d(num_features = layers[0]))\n",
    "    for i in range(len(layers) - 2):\n",
    "        constructor.append(nn.Linear(in_features = layers[i],\n",
    "                                     out_features = layers[i + 1]))\n",
    "        constructor.append(hidden_activation)\n",
    "        if hidden_batchnorm:\n",
    "            constructor.append(nn.BatchNorm1d(num_features = layers[i + 1]))\n",
    "        constructor.append(nn.Dropout(p=dropout_prob))\n",
    "    \n",
    "    constructor.append(nn.Linear(in_features = layers[-2], out_features = layers[-1]))\n",
    "    if final_activation is not None:\n",
    "        constructor.append(final_activation)\n",
    "    result = nn.Sequential(*constructor)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA ANALYSIS SUPPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse_matrix_update(predictions, labels, confusion_matrix):\n",
    "    # Update 'confusion_matrix' according the the prodictions/labels vectors.\n",
    "    # Confusion_matrix rows are actual labels, and columns predictions. E.g. row 0 \n",
    "    # tells how the classifier predicted '0', (0,0) represents correct predictions, \n",
    "    # (0,1) is how many times a '0' was classified as a '1'\n",
    "    for pre, lbl in zip(predictions, labels):\n",
    "        confusion_matrix[lbl,pre] += 1\n",
    "def confuse_matrix_accuracy(cm):\n",
    "    return 0.0 if cm.sum() == 0 else cm.trace()/cm.sum()\n",
    "if False:\n",
    "    cm = np.zeros((10,10))\n",
    "    pred=torch.tensor([2,9,8,6])\n",
    "    lab =torch.tensor([2,9,8,4])\n",
    "    confuse_matrix_update(pred,lab,cm)\n",
    "    confuse_matrix_update(pred,lab,cm)\n",
    "    print(cm, confuse_matrix_accuracy(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confuse_matrix(VAE, test_loader = None):\n",
    "    # print confuse_matrix for 'VAE' which is assumed to have function 'classifier'\n",
    "    # and variable 'device' indicating cpu or cuda.\n",
    "    if test_loader == None:\n",
    "        test_loader = binarized_mnist_test_loader\n",
    "    confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "    for images_test,labels_test in test_loader:\n",
    "        images_test = images_test.to(VAE.device)\n",
    "        classifications = VAE.classifier(images_test.view(-1,28*28))\n",
    "        preds = torch.argmax(classifications,1)\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "    print(confuse_matrix)\n",
    "    print(\"Classifier accuracy: %.3f\" % confuse_matrix_accuracy(confuse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.valid_losses = []\n",
    "        self.valid_accuracies = []\n",
    "        self.test_losses = []\n",
    "        self.test_accuracies = []\n",
    "        \n",
    "        self.train_loss_buffer = []\n",
    "        self.train_labels_buffer = []\n",
    "        self.train_preds_buffer = []\n",
    "        self.valid_loss_buffer = []\n",
    "        self.valid_labels_buffer = []\n",
    "        self.valid_preds_buffer = []\n",
    "        self.test_loss_buffer = []\n",
    "        self.test_labels_buffer = []\n",
    "        self.test_preds_buffer = []\n",
    "    \n",
    "    def append_train(self, loss: Tensor, preds: Tensor = None, targets: Tensor = None):\n",
    "        self.train_loss_buffer = np.append(self.train_loss_buffer, loss.cpu().detach().numpy())\n",
    "        if preds is not None and targets is not None:\n",
    "            self.train_labels_buffer = np.append(self.train_labels_buffer, targets)\n",
    "            self.train_preds_buffer = np.append(self.train_preds_buffer, preds.cpu().detach().numpy())\n",
    "    \n",
    "    def append_valid(self, loss: Tensor, preds: Tensor = None, targets: Tensor = None):\n",
    "        self.valid_loss_buffer = np.append(self.valid_loss_buffer, loss.cpu().detach().numpy())\n",
    "        if preds is not None and targets is not None:\n",
    "            self.valid_labels_buffer = np.append(self.valid_labels_buffer, targets)\n",
    "            self.valid_preds_buffer = np.append(self.valid_preds_buffer, preds.cpu().detach().numpy())\n",
    "    \n",
    "    def append_test(self, loss: Tensor, preds: Tensor = None, targets: Tensor = None):\n",
    "        self.test_loss_buffer = np.append(self.test_loss_buffer, loss.cpu().detach().numpy())\n",
    "        if preds is not None and targets is not None:\n",
    "            self.test_labels_buffer = np.append(self.test_labels_buffer, targets)\n",
    "            self.test_preds_buffer = np.append(self.test_preds_buffer, preds.cpu().detach().numpy())\n",
    "\n",
    "    def plot(self):\n",
    "        # Train processing\n",
    "        self.train_losses = np.append(self.train_losses, np.mean(self.train_loss_buffer))\n",
    "        self.train_loss_buffer = []\n",
    "        train_acc = accuracy_score(self.train_labels_buffer, self.train_preds_buffer)\n",
    "        self.train_preds_buffer = []\n",
    "        self.train_labels_buffer = []\n",
    "        self.train_accuracies = np.append(self.train_accuracies, train_acc)\n",
    "        # Valid processing\n",
    "        self.valid_losses = np.append(self.valid_losses, np.mean(self.valid_loss_buffer))\n",
    "        self.valid_loss_buffer = []\n",
    "        valid_acc = accuracy_score(self.valid_labels_buffer, self.valid_preds_buffer)\n",
    "        self.valid_labels_buffer = []\n",
    "        self.valid_preds_buffer = []\n",
    "        self.valid_accuracies = np.append(self.valid_accuracies, valid_acc)\n",
    "        # Test processing\n",
    "        self.test_losses = np.append(self.test_losses, np.mean(self.test_loss_buffer))\n",
    "        self.test_loss_buffer = []\n",
    "        test_acc = accuracy_score(self.test_labels_buffer, self.test_preds_buffer)\n",
    "        self.test_labels_buffer = []\n",
    "        self.test_preds_buffer = []\n",
    "        self.test_accuracies = np.append(self.test_accuracies, test_acc)\n",
    "        \n",
    "        # Display\n",
    "        clear_output(wait=True)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5), squeeze=False)\n",
    "        ax = axs[0, 0]\n",
    "        ax.set_title('Loss')\n",
    "        ax.plot(self.train_losses, label = 'Training')\n",
    "        ax.plot(self.valid_losses, label = 'Validation')\n",
    "        ax.plot(self.test_losses, label = 'Test')\n",
    "        ax.legend()\n",
    "        \n",
    "        ax = axs[0, 1]\n",
    "        ax.set_title('Accuracy')\n",
    "        ax.plot(self.train_accuracies, label = 'Training')\n",
    "        ax.plot(self.valid_accuracies, label = 'Validation')\n",
    "        ax.plot(self.test_accuracies, label = 'Test')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        tmp_img = \"tmp_ae_out.png\"\n",
    "        plt.savefig(tmp_img)\n",
    "        plt.close(fig)\n",
    "        display(Image(filename=tmp_img))\n",
    "        \n",
    "        print(\"Training Loss: %.3f, Validation Loss: %.3f, Test Loss: %.3f\" %\n",
    "              (self.train_losses[-1], self.valid_losses[-1], self.test_losses[-1]))\n",
    "        print(\"Training Accuracy: %.3f, Validation Accuracy: %.3f, Test Accuracy: %.3f\" %\n",
    "              (self.train_accuracies[-1], self.valid_accuracies[-1], self.test_accuracies[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla FFNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FFNN IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classification model\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_shape: torch.Size, num_classes: int, hidden_shape: []) -> None:\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        \n",
    "        # Core params\n",
    "        self.input_shape = input_shape\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.epoch = 0\n",
    "        \n",
    "        # Model construction\n",
    "        model_shape = [self.observation_features]\n",
    "        model_shape.extend(hidden_shape)\n",
    "        model_shape.append(num_classes)\n",
    "        self.model = FF_NetworkConstructor(layers = model_shape,\n",
    "                                           pre_batchnorm = False,\n",
    "                                           hidden_batchnorm = True,\n",
    "                                           hidden_activation = nn.ReLU(),\n",
    "                                           dropout_prob = 0.5,\n",
    "                                           final_activation = nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FFNN TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN_Trainer:\n",
    "    def __init__(self,\n",
    "                 network: SimpleClassifier,\n",
    "                 train_set: DataLoader,\n",
    "                 valid_set: DataLoader,\n",
    "                 test_set: DataLoader):\n",
    "        self.network = network\n",
    "        self.train_set = train_set\n",
    "        self.valid_set = valid_set\n",
    "        self.test_set = test_set\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=0.001)\n",
    "        self.plotter = Plotter()\n",
    "\n",
    "    def train(self):\n",
    "        self.network.train()\n",
    "        for images, labels in self.train_set:\n",
    "            self.optimizer.zero_grad()\n",
    "            classifications = self.network(images)\n",
    "            loss = self.criterion(classifications, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        self.network.epoch += 1\n",
    "    \n",
    "    def test(self):\n",
    "        self.network.eval()\n",
    "        \n",
    "        for images, labels in self.train_set:\n",
    "            classifications = self.network(images)\n",
    "            loss = self.criterion(classifications, labels)\n",
    "            self.plotter.append_train(loss, torch.argmax(classifications, 1), labels)\n",
    "        \n",
    "        for images, labels in self.valid_set:\n",
    "            classifications = self.network(images)\n",
    "            loss = self.criterion(classifications, labels)\n",
    "            self.plotter.append_valid(loss, torch.argmax(classifications, 1), labels)\n",
    "        \n",
    "        for images, labels in self.test_set:\n",
    "            classifications = self.network(images)\n",
    "            loss = self.criterion(classifications, labels)\n",
    "            self.plotter.append_test(loss, torch.argmax(classifications, 1), labels)\n",
    "        \n",
    "        self.plotter.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAE IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF5c_hYM8v-o"
   },
   "outputs": [],
   "source": [
    "# Summarize values per sample\n",
    "def reduce(x: Tensor) -> Tensor:\n",
    "    return x.view(x.size(0), -1).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHWnmyLfrTBF"
   },
   "outputs": [],
   "source": [
    "# Define hidden layer topology - list of sizes of hidden layers\n",
    "encoder_dimensions = [512, 256, 128]\n",
    "decoder_dimensions = [128, 256, 512]\n",
    "apply_per_layer_batchnorm = False\n",
    "\n",
    "# Implement VAE\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_shape:torch.Size, latent_features:int) -> None:\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "\n",
    "        # Core parameters\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        \n",
    "        # Dynamically constructing the encoder network\n",
    "        encoder_constructor = []\n",
    "        encoder_constructor.append(nn.Linear(in_features=self.observation_features, out_features=encoder_dimensions[0]))\n",
    "        encoder_constructor.append(nn.ReLU())\n",
    "        if apply_per_layer_batchnorm:\n",
    "            encoder_constructor.append(nn.BatchNorm1d(num_features=encoder_dimensions[0]))\n",
    "        for i in range(len(encoder_dimensions)-1):\n",
    "            encoder_constructor.append(nn.Linear(in_features=encoder_dimensions[i], out_features=encoder_dimensions[i+1]))\n",
    "            encoder_constructor.append(nn.ReLU())\n",
    "            if apply_per_layer_batchnorm:\n",
    "                encoder_constructor.append(nn.BatchNorm1d(num_features=encoder_dimensions[i+1]))\n",
    "        encoder_constructor.append(nn.Linear(in_features=encoder_dimensions[-1], out_features=2*self.latent_features))\n",
    "        self.encoder = nn.Sequential(*encoder_constructor)\n",
    "\n",
    "        # Dynamically constructing the decoder network\n",
    "        decoder_constructor = []\n",
    "        decoder_constructor.append(nn.Linear(in_features=self.latent_features, out_features=decoder_dimensions[0]))\n",
    "        decoder_constructor.append(nn.ReLU())\n",
    "        if apply_per_layer_batchnorm:\n",
    "            decoder_constructor.append(nn.BatchNorm1d(num_features=decoder_dimensions[0]))\n",
    "        for i in range(len(decoder_dimensions)-1):\n",
    "            decoder_constructor.append(nn.Linear(in_features=decoder_dimensions[i], out_features=decoder_dimensions[i+1]))\n",
    "            decoder_constructor.append(nn.ReLU())\n",
    "            if apply_per_layer_batchnorm:\n",
    "                decoder_constructor.append(nn.BatchNorm1d(num_features=decoder_dimensions[i+1]))\n",
    "        decoder_constructor.append(nn.Linear(in_features=decoder_dimensions[-1], out_features=self.observation_features))\n",
    "        self.decoder = nn.Sequential(*decoder_constructor)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda:0\"\n",
    "            self.encoder.cuda()\n",
    "            self.decoder.cuda()\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "            self.encoder.cpu()\n",
    "            self.decoder.cpu()\n",
    "        \n",
    "    # Encode input into posterior distribution\n",
    "    def encode(self, x: Tensor) -> Distribution:\n",
    "        h_x = self.encoder(x)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "        result = ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        result.mu = result.mu.to(self.device)\n",
    "        result.sigma = result.sigma.to(self.device)\n",
    "        return result\n",
    "    \n",
    "    # Decode latent variables into reconstruction\n",
    "    def decode(self, z: Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(z)\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits=px_logits)\n",
    "    \n",
    "    # Get the prior distribution\n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        result = ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        result.mu = result.mu.to(self.device)\n",
    "        result.sigma = result.sigma.to(self.device)\n",
    "        return result\n",
    "    \n",
    "    # Sample from a provided distribution\n",
    "    def sample(self, distribution: ReparameterizedDiagonalGaussian) -> Tensor:\n",
    "        return distribution.rsample()\n",
    "    \n",
    "    # Compute the ELBO\n",
    "    def elbo(self, prior: Distribution, posterior: Distribution, reconstruction: Distribution, x: Tensor, z: Tensor) -> float:\n",
    "        tst = reconstruction.sample().to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        z = z.to(self.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        log_px = reduce(reconstruction.log_prob(x))\n",
    "        log_pz = reduce(prior.log_prob(z))\n",
    "        log_qz = reduce(posterior.log_prob(z))\n",
    "        kl = log_qz - log_pz\n",
    "        elbo = log_px - kl\n",
    "        return elbo\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Dict[str, Any]:\n",
    "        # Figure out where model currently is located and update 'self.device'. \n",
    "        # Makes it possible to dynamically move model between cpu and cuda, after it has been initialized.\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            self.device = \"cuda:0\"\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "        # flatten the input\n",
    "        x = x.to(self.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.encode(x)\n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        z = qz.rsample()\n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.decode(z)\n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAE TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "class VAE_Trainer:\n",
    "    def __init__(self, network: VariationalAutoEncoder, train: DataLoader, test: DataLoader):\n",
    "        self.VAE = network\n",
    "        self.train_data = train\n",
    "        self.test_data = test\n",
    "        self.optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "    \n",
    "    def train(self):\n",
    "        self.VAE.train()\n",
    "        for images, labels in self.train_data:\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.VAE(images)\n",
    "            loss = -self.VAE.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def test(self):\n",
    "        self.VAE.eval()\n",
    "        losses = []\n",
    "        i = 0\n",
    "        for images, labels in self.test_data:\n",
    "            outputs = self.VAE(images)\n",
    "            elbos = self.VAE.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).cpu().detach().numpy()\n",
    "            losses = np.append(losses, elbos)\n",
    "        loss = -np.mean(losses)\n",
    "        print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2 VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: torch.Size,\n",
    "                 latent_features: int,\n",
    "                 classes: int, \n",
    "                 hidden_layers_preclass: [], \n",
    "                 hidden_layers_postclass: [], \n",
    "                 hidden_layers_classification: [],\n",
    "                 hidden_layers_decoder: []):\n",
    "        super(M2_VAE, self).__init__()\n",
    "        \n",
    "        # Core params\n",
    "        self.input_shape = input_shape\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        self.register_buffer('classification_prior_params', torch.full(torch.Size([1, classes]), 1 / classes))\n",
    "        self.classes = classes\n",
    "        # Having epochs here makes it possible to continue training, with correct epochs counting\n",
    "        self.epochs = 0\n",
    "        \n",
    "        # Cuda enabling\n",
    "        if torch.cuda.is_available():\n",
    "            self.use_cuda = True\n",
    "            self.device = \"cuda:0\"\n",
    "        else:\n",
    "            self.use_cuda = False\n",
    "            self.device = \"cpu\"\n",
    "        \n",
    "        # Classifier construction\n",
    "        classifier_shape = [self.observation_features]\n",
    "        classifier_shape.extend(hidden_layers_classification)\n",
    "        classifier_shape.append(classes)\n",
    "        self.classifier = FF_NetworkConstructor(layers = classifier_shape,\n",
    "                                                pre_batchnorm = False,\n",
    "                                                hidden_batchnorm = True,\n",
    "                                                hidden_activation = nn.ReLU(),\n",
    "                                                dropout_prob = 0.5,\n",
    "                                                final_activation = None)\n",
    "        \n",
    "        # Pre-classification network construction\n",
    "        preclass_shape = [self.observation_features]\n",
    "        preclass_shape.extend(hidden_layers_preclass)\n",
    "        self.preclass_encoder = FF_NetworkConstructor(layers = preclass_shape,\n",
    "                                                      pre_batchnorm = False,\n",
    "                                                      hidden_batchnorm = True,\n",
    "                                                      hidden_activation = nn.ReLU(),\n",
    "                                                      dropout_prob = 0.5,\n",
    "                                                      final_activation = nn.ReLU())\n",
    "        \n",
    "        # Post-classification network construction\n",
    "        postclass_shape = [hidden_layers_preclass[-1] + classes]\n",
    "        postclass_shape.extend(hidden_layers_postclass)\n",
    "        postclass_shape.append(latent_features * 2)\n",
    "        self.postclass_encoder = FF_NetworkConstructor(layers = postclass_shape,\n",
    "                                                       pre_batchnorm = False,\n",
    "                                                       hidden_batchnorm = True,\n",
    "                                                       hidden_activation = nn.ReLU(),\n",
    "                                                       dropout_prob = 0.5,\n",
    "                                                       final_activation = None)\n",
    "        \n",
    "        # Decoder construction\n",
    "        decoder_shape = [latent_features + classes]\n",
    "        decoder_shape.extend(hidden_layers_decoder)\n",
    "        decoder_shape.append(self.observation_features)\n",
    "        self.decoder = FF_NetworkConstructor(layers = decoder_shape,\n",
    "                                             pre_batchnorm = False,\n",
    "                                             hidden_batchnorm = True,\n",
    "                                             hidden_activation = nn.ReLU(),\n",
    "                                             dropout_prob = 0.5,\n",
    "                                             final_activation = None)\n",
    "        \n",
    "        # Move networks to cuda if available\n",
    "        if self.use_cuda:\n",
    "            self.classifier.cuda()\n",
    "            self.preclass_encoder.cuda()\n",
    "            self.postclass_encoder.cuda()\n",
    "            self.decoder.cuda()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        for layers in self.children():\n",
    "            for layer in layers:\n",
    "                if hasattr(layer, 'reset_parameters'):\n",
    "                    layer.reset_parameters()\n",
    "        self.epochs = 0\n",
    "\n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        result = ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        result.mu = result.mu.to(self.device)\n",
    "        result.sigma = result.sigma.to(self.device)\n",
    "        return result\n",
    "    \n",
    "    def classification_prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_classification_prior_params = self.classification_prior_params.expand(batch_size, \n",
    "                                                                                    *self.classification_prior_params.shape[-1:])\n",
    "        result = Categorical(probs = local_classification_prior_params)\n",
    "        return result\n",
    "    \n",
    "    def classification_posterior(self, x: Tensor) -> Distribution:\n",
    "        result = self.classifier(x)\n",
    "        result = result.view(-1, self.classes)\n",
    "        result = Categorical(logits = result)\n",
    "        return result\n",
    "    \n",
    "    def classification_entropy(self, qy: Tensor) -> float:\n",
    "        qy = qy * torch.log(qy)\n",
    "        return -qy.sum(1)\n",
    "        \n",
    "    def encode(self, x: Tensor, y: Tensor = None) -> Tensor:\n",
    "        # Classify if no classification is provided\n",
    "        if y is None:\n",
    "            y = self.classifier(x)\n",
    "        # Encode input\n",
    "        result = self.preclass_encoder(x)\n",
    "        result = torch.cat((result, y), 1)\n",
    "        result = self.postclass_encoder(result)\n",
    "        mu, log_sigma =  result.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def decode(self, z: Tensor, y: Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(torch.cat((z, y), 1))\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits = px_logits)\n",
    "    \n",
    "    def onehot(self, y: int):\n",
    "        result = torch.zeros(y.shape[0], self.classes).to(self.device)\n",
    "        for i in range(len(y)):\n",
    "            result[i][y[i]] = 1\n",
    "        return result\n",
    "    \n",
    "    def loss(self,\n",
    "             px: Distribution, \n",
    "             py: Distribution, \n",
    "             pz: Distribution, \n",
    "             qy: Distribution, \n",
    "             qz: Distribution, \n",
    "             x: Tensor,\n",
    "             y: int, \n",
    "             z: Tensor,\n",
    "             alpha: float,\n",
    "             debug: bool = False) -> float:\n",
    "        x = x.to(self.device)\n",
    "        z = z.to(self.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        py_logprob = py.logits.to(self.device)\n",
    "        \n",
    "        # If labels are not provided, sample from classification posterior\n",
    "        if y is None:\n",
    "            if True:\n",
    "                # Paralel calcution giving 40% speedup compared to serial version below.\n",
    "                x2 = x.repeat(10,1)\n",
    "                y2 = torch.Tensor(0)\n",
    "                for i in range(10):\n",
    "                    y2 = torch.cat( (y2, torch.Tensor([i]).expand(x.shape[0])))\n",
    "                y2 = y2.to(self.device)\n",
    "                outputs = self.forward(x2, y2)\n",
    "                px_logprob = outputs['px'].log_prob(x2.view(10*x.shape[0],-1)).sum(dim=1).view(-1,10)\n",
    "                qz_logprob = outputs['qz'].log_prob(outputs['z']).sum(dim=1).view(-1, 10)\n",
    "                pz_logprob = outputs['pz'].log_prob(outputs['z']).sum(dim=1).view(-1, 10)\n",
    "            else:\n",
    "                # Original serial calculation. Kept as fall-back until parallel version has been more tested\n",
    "                px_logprob = torch.Tensor(0).to(self.device)\n",
    "                qz_logprob = torch.Tensor(0).to(self.device)\n",
    "                pz_logprob = torch.Tensor(0).to(self.device)\n",
    "                for i in range(10):\n",
    "                    _y = torch.Tensor([i]).expand(x.shape[0])\n",
    "                    outputs = self.forward(x, _y)\n",
    "                    px_logprob = torch.cat((px_logprob, outputs['px'].log_prob(x).sum(dim = 1).view(-1, 1)), 1)\n",
    "                    qz_logprob = torch.cat((qz_logprob, outputs['qz'].log_prob(outputs['z']).sum(dim = 1).view(-1, 1)), 1)\n",
    "                    pz_logprob = torch.cat((pz_logprob, outputs['pz'].log_prob(outputs['z']).sum(dim = 1).view(-1, 1)), 1)\n",
    "            \n",
    "            L = -(px_logprob + py_logprob + pz_logprob - qz_logprob)\n",
    "            U = -(torch.mul(qy.probs, -L).sum(1) + self.classification_entropy(qy.probs))\n",
    "            J = U\n",
    "            return J\n",
    "        else:\n",
    "            y = y.to(self.device)\n",
    "            y = y.view(-1, 1)\n",
    "            px_logprob = px.log_prob(x).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            qz_logprob = qz.log_prob(z).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            pz_logprob = pz.log_prob(z).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            L = -(px_logprob + py_logprob + pz_logprob - qz_logprob)\n",
    "            J = L.gather(1, y)\n",
    "            J_alpha = J - (alpha * qy.logits.gather(1, y))\n",
    "            return J_alpha\n",
    "    \n",
    "    def forward(self, x: Tensor, y: int = None, debug: bool = False) -> Dict[str, Any]:\n",
    "        x = x.to(self.device) # Move to cuda if applicable\n",
    "        x = x.view(x.size(0), -1) # Flatten image input\n",
    "        qy = self.classification_posterior(x) # Classification posterior q(y|x)\n",
    "        py = self.classification_prior(batch_size = x.size(0)) # Classification prior p(y)\n",
    "        pz = self.prior(batch_size=x.size(0)) # Prior p(z)\n",
    "        if y is None: # If labels are not provided, sample from classification posterior\n",
    "            try:\n",
    "                y = qy.sample()\n",
    "            except:\n",
    "                print(self.classifier(x))\n",
    "                raise Exception(\"QY sample error\")\n",
    "        \n",
    "        y = y.to(self.device)\n",
    "        y = y.int()\n",
    "        y = self.onehot(y)\n",
    "        qz = self.encode(x, y) # Approximate posterior q(z|x, y)\n",
    "        z = qz.rsample() # Sample the posterior\n",
    "        px = self.decode(z, y) # Reconstruction p(x|z, y) = B(x | g(z, y))\n",
    "        \n",
    "        return {'px': px, 'py': py, 'pz': pz, 'qy': qy, 'qz': qz, 'z': z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE_Trainer:\n",
    "    def __init__(self,\n",
    "                 network:M2_VAE              = None,\n",
    "                 train_labelled:DataLoader   = None,\n",
    "                 train_unlabelled:DataLoader = None,\n",
    "                 valid:DataLoader            = None,\n",
    "                 test:DataLoader             = None,\n",
    "                 labelled_ratio:int          = 1,\n",
    "                 alpha:float                 = 0.1,\n",
    "                 verbose:int                 = 0):\n",
    "        self.model            = network          if network          != None else TestM2\n",
    "        self.train_labelled   = train_labelled   if train_labelled   != None else binarized_mnist_train_loader_labelled\n",
    "        self.train_unlabelled = train_unlabelled if train_unlabelled != None else binarized_mnist_train_loader_unlabelled\n",
    "        self.valid_data       = valid            if valid            != None else binarized_mnist_train_loader_validation\n",
    "        self.test_data        = test             if test             != None else binarized_mnist_test_loader\n",
    "        self.alpha = alpha\n",
    "        self.training_data = defaultdict(list)\n",
    "        self.validation_data = defaultdict(list)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.labelled_ratio = labelled_ratio\n",
    "        self.unlbl_bcnt = 0\n",
    "        self.lbl_bcnt = 0\n",
    "        self.tst_bcnt = 0\n",
    "        self.verbose = verbose\n",
    "        self.plotter = Plotter()\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        if self.train_unlabelled is not None:\n",
    "            for images, labels in self.train_unlabelled:\n",
    "                self.unlbl_bcnt += 1\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images, None)\n",
    "                loss = self.model.loss(outputs['px'], \n",
    "                                       outputs['py'], \n",
    "                                       outputs['pz'], \n",
    "                                       outputs['qy'], \n",
    "                                       outputs['qz'],\n",
    "                                       images, \n",
    "                                       None,\n",
    "                                       outputs['z'],\n",
    "                                       self.alpha).mean()\n",
    "                for i in range(self.labelled_ratio):\n",
    "                    img_lbl, lbl_lbl = next(iter(self.train_unlabelled))\n",
    "                    outputs = self.model(img_lbl, lbl_lbl)\n",
    "                    loss += self.model.loss(outputs['px'], \n",
    "                                            outputs['py'], \n",
    "                                            outputs['pz'], \n",
    "                                            outputs['qy'], \n",
    "                                            outputs['qz'],\n",
    "                                            img_lbl, \n",
    "                                            lbl_lbl,\n",
    "                                            outputs['z'],\n",
    "                                            self.alpha).mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        else:\n",
    "            for images, labels in self.train_labelled:\n",
    "                self.lbl_bcnt += 1\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images, labels)\n",
    "                loss = self.model.loss(outputs['px'], \n",
    "                                       outputs['py'], \n",
    "                                       outputs['pz'], \n",
    "                                       outputs['qy'], \n",
    "                                       outputs['qz'],\n",
    "                                       images, \n",
    "                                       labels,\n",
    "                                       outputs['z'],\n",
    "                                       self.alpha).mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        self.model.epochs += 1\n",
    "    \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        i = 0\n",
    "        epoch_data = defaultdict(list)\n",
    "        for images, labels in self.train_labelled:\n",
    "            self.tst_bcnt += 1\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha).mean()\n",
    "            epoch_data['loss'] += [loss.item()]\n",
    "            classifications = self.model.classifier(images.view(-1,28*28).to(self.model.device))\n",
    "            preds = torch.argmax(classifications,1)\n",
    "            self.plotter.append_train(loss, preds, labels)\n",
    "\n",
    "        for images, labels in self.valid_data:\n",
    "            self.tst_bcnt += 1\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha).mean()\n",
    "            epoch_data['loss'] += [loss.item()]\n",
    "            classifications = self.model.classifier(images.view(-1,28*28).to(self.model.device))\n",
    "            preds = torch.argmax(classifications,1)\n",
    "            self.plotter.append_valid(loss, preds, labels)\n",
    "\n",
    "        for images, labels in self.test_data:\n",
    "            self.tst_bcnt += 1\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha).mean()\n",
    "            epoch_data['loss'] += [loss.item()]\n",
    "            classifications = self.model.classifier(images.view(-1,28*28).to(self.model.device))\n",
    "            preds = torch.argmax(classifications,1)\n",
    "            self.plotter.append_test(loss, preds, labels)\n",
    "\n",
    "        self.plotter.plot()\n",
    "        #for k, v in epoch_data.items():\n",
    "        #    self.validation_data[k] += [np.mean(v)]\n",
    "        #self.validation_data['class_accu'] += [confuse_matrix_accuracy(confuse_matrix)]\n",
    "\n",
    "        #print(\"epoch=%d  test_loss=%.2f  class_accu=%.3f\" % (self.model.epochs, \n",
    "        #                                                     self.validation_data['loss'][-1], \n",
    "        #                                                     self.validation_data['class_accu'][-1]))\n",
    "        #print(\"         unlbl_bcnt=%d, lbl_bcnt=%d, tst_bcnt=%d\" % (self.unlbl_bcnt,\n",
    "        #                                                            self.lbl_bcnt,\n",
    "        #                                                            self.tst_bcnt)) if self.verbose > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple classifier baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100 OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "ffnn = SimpleClassifier(sample.flatten().shape, 10, [500, 250])\n",
    "loader_setup(labelled_size=100)\n",
    "trainer = FFNN_Trainer(ffnn,\n",
    "                       binarized_mnist_train_loader_labelled,\n",
    "                       binarized_mnist_train_loader_validation,\n",
    "                       binarized_mnist_test_loader)\n",
    "epochs = 10\n",
    "fn = \"./ffnn_100_%dep.pt\" % epochs\n",
    "if False and os.path.isfile(fn):\n",
    "    ffnn.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(ffnn.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1000 OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "ffnn = SimpleClassifier(sample.flatten().shape, 10, [500, 250])\n",
    "loader_setup(labelled_size=1000)\n",
    "trainer = FFNN_Trainer(ffnn,\n",
    "                       binarized_mnist_train_loader_labelled,\n",
    "                       binarized_mnist_train_loader_validation,\n",
    "                       binarized_mnist_test_loader)\n",
    "epochs = 10\n",
    "fn = \"./ffnn_1000_%dep.pt\" % epochs\n",
    "if False and os.path.isfile(fn):\n",
    "    ffnn.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(ffnn.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10000 OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "ffnn = SimpleClassifier(sample.flatten().shape, 10, [500, 250])\n",
    "loader_setup(labelled_size=10000)\n",
    "trainer = FFNN_Trainer(ffnn,\n",
    "                       binarized_mnist_train_loader_labelled,\n",
    "                       binarized_mnist_train_loader_validation,\n",
    "                       binarized_mnist_test_loader)\n",
    "epochs = 10\n",
    "fn = \"./ffnn_10000_%dep.pt\" % epochs\n",
    "if False and os.path.isfile(fn):\n",
    "    ffnn.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(ffnn.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard VAE (M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(0)[0]\n",
    "testVAE = VariationalAutoEncoder(sample.flatten().shape, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train the VAE\n",
    "trainer = VAE_Trainer(testVAE, binarized_mnist_train_loader_unlabelled, binarized_mnist_test_loader)\n",
    "\n",
    "testVAE_fn = \"./M1_119ls_base_200ep.pt\"\n",
    "if os.path.isfile(testVAE_fn):\n",
    "    testVAE.load_state_dict(torch.load(testVAE_fn))\n",
    "    print(\"Loaded testVAE model from %s\" % testVAE_fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    epochs = 200\n",
    "    for i in range(epochs):\n",
    "        print(\"Training epoch \", i)\n",
    "        trainer.train()\n",
    "        print(\"Testing epoch \", i)\n",
    "        trainer.test()\n",
    "    torch.save(testVAE.state_dict(), testVAE_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100/40K LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loader_setup(labelled_size=100, unlabelled_size=400)\n",
    "trainer = M2_VAE_Trainer(TestM2,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.1)\n",
    "epochs = 10\n",
    "fn = \"m2_class_100_labelled_%dep.pt\" % epochs\n",
    "if False and os.path.isfile(fn):\n",
    "    TestM2.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(TestM2.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1K/40K LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loader_setup(labelled_size=1000, unlabelled_size=40000)\n",
    "trainer = M2_VAE_Trainer(TestM2,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.1)\n",
    "epochs = 10\n",
    "fn = \"m2_class_1k_labelled_%dep.pt\" % epochs\n",
    "if os.path.isfile(fn):\n",
    "    TestM2.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(TestM2.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10K/40K LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loader_setup(labelled_size=10000, unlabelled_size=40000)\n",
    "trainer = M2_VAE_Trainer(TestM2,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.1)\n",
    "epochs = 10\n",
    "fn = \"m2_class_10k_labelled_%dep.pt\" % epochs\n",
    "if os.path.isfile(fn):\n",
    "    TestM2.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(TestM2.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**50K LABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loader_setup(labelled_size=50000)\n",
    "trainer = M2_VAE_Trainer(TestM2,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.1)\n",
    "epochs = 10\n",
    "fn = \"m2_class_50k_labelled_%dep.pt\" % epochs\n",
    "if os.path.isfile(fn):\n",
    "    TestM2.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(TestM2.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2 - Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5-DIMENSIONAL LATENT SPACE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loader_setup(labelled_size=10000, unlabelled_size=40000)\n",
    "trainer = M2_VAE_Trainer(TestM2,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.1)\n",
    "epochs = 10\n",
    "fn = \"./style_transfer_5D_%dep.pt\" % epochs\n",
    "if os.path.isfile(fn):\n",
    "    TestM2.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(TestM2.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestM2.eval()\n",
    "a = random.choices(binarized_mnist_train_data,k=10)\n",
    "b = [x[0] for x in a]\n",
    "img = torch.stack(b)\n",
    "b = [x[1] for x in a]\n",
    "lbl = torch.Tensor(b)\n",
    "fig, axs = plt.subplots(10, 11, figsize=(10, 10), squeeze=False)\n",
    "\n",
    "outputs = TestM2(img, lbl)\n",
    "z = outputs['z']\n",
    "\n",
    "for i in range(len(img)):\n",
    "    axs[i, 0].imshow(img[i], cmap='gray')\n",
    "    axs[i, 0].axis('off')\n",
    "    for j in range(10):\n",
    "        image = TestM2.decode(z[i].reshape(1, -1), TestM2.onehot(torch.Tensor([j]).int())).sample().view(28,28).cpu()\n",
    "        axs[i, j + 1].imshow(image, cmap='gray')\n",
    "        axs[i, j + 1].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**50-DIMENSIONAL LATENT SPACE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                50, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loader_setup(labelled_size=10000, unlabelled_size=40000)  # skip unlabelled training\n",
    "trainer = M2_VAE_Trainer(TestM2,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.1)\n",
    "epochs = 10\n",
    "fn = \"./style_transfer_50D_%dep.pt\" % epochs\n",
    "if os.path.isfile(fn):\n",
    "    TestM2.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(TestM2.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestM2.eval()\n",
    "a = random.choices(binarized_mnist_train_data,k=10)\n",
    "b = [x[0] for x in a]\n",
    "img = torch.stack(b)\n",
    "b = [x[1] for x in a]\n",
    "lbl = torch.Tensor(b)\n",
    "fig, axs = plt.subplots(10, 11, figsize=(10, 10), squeeze=False)\n",
    "\n",
    "outputs = TestM2(img, lbl)\n",
    "z = outputs['z']\n",
    "\n",
    "for i in range(len(img)):\n",
    "    axs[i, 0].imshow(img[i], cmap='gray')\n",
    "    axs[i, 0].axis('off')\n",
    "    for j in range(10):\n",
    "        image = TestM2.decode(z[i].reshape(1, -1), TestM2.onehot(torch.Tensor([j]).int())).sample().view(28,28).cpu()\n",
    "        axs[i, j + 1].imshow(image, cmap='gray')\n",
    "        axs[i, j + 1].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxXpiIwXGYvY"
   },
   "source": [
    "**SUBTASK 2.1.2: Plot 8x8 random samples from MNIST data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "ixxaXCQCO_dB",
    "outputId": "95e6471d-aa7d-460d-e80a-e9e0b9080403"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(mnist_train_loader))\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(\"%s\" % (labels[i].item()))\n",
    "    ax.axis('off')\n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLIEWEXOoOpt"
   },
   "source": [
    "**SUBTASK 2.1.4: Plot binarized MNIST samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "_Qf9sLMqhyaQ",
    "outputId": "9701d2a4-a4fc-4f79-c854-0ed0fde5995c"
   },
   "outputs": [],
   "source": [
    "# QUESTION: are we doing statistical sampling of the greytones in the picture, so it picture looks slightly\n",
    "#           different whenever DataLoader delivers it again ?\n",
    "#\n",
    "# ANSWER: yes, below plot same image a couple of times\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3), squeeze=False)\n",
    "for ax in axs.flat:\n",
    "    sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "    assert torch.max(sample) == 1.0\n",
    "    assert torch.min(sample) == 0.0\n",
    "    ax.imshow(sample, cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "-9Jj6BslTiPt",
    "outputId": "2c88f850-a28e-4b62-8280-10c5e8daa311"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(binarized_mnist_train_loader_labelled))\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(\"%s\" % (labels[i].item()))\n",
    "    ax.axis('off')\n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xht6E_a-Mee"
   },
   "source": [
    "**SUBTASK 2.2.1.2: Print samples from untrained VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxhZisS33nwM",
    "outputId": "e40f6ce3-9970-43db-9b5f-8cea8c7e372e"
   },
   "outputs": [],
   "source": [
    "# Instantiate a VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(0)[0]\n",
    "testVAE = VariationalAutoEncoder(sample.flatten().shape, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Decoding sample from prior\n",
    "testVAE.eval()\n",
    "\n",
    "prior = testVAE.prior(64)\n",
    "prior_sample = testVAE.sample(prior)\n",
    "decoded_prior_sample = testVAE.decode(prior_sample)\n",
    "sampled_decode_content = decoded_prior_sample.sample().view(64, 28, 28)\n",
    "\n",
    "sampled_decode_content = sampled_decode_content.cpu()  # note that .cpu() works differently for tensor & model\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "cwWZmv9Y9Urq",
    "outputId": "a4b073a4-af3f-4872-fc57-3eb7afa0f798"
   },
   "outputs": [],
   "source": [
    "# Method 2: Reconstruction of input from binarized MNIST\n",
    "a = random.choices(binarized_mnist_train_data,k=64)\n",
    "b = [x[0] for x in a]\n",
    "img = torch.stack(b).to(testVAE.device)\n",
    "sampled_decode_content = testVAE(img)['px'].sample().view(-1,28,28)\n",
    "\n",
    "sampled_decode_content = sampled_decode_content.cpu()\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgglyZU6FNZl"
   },
   "source": [
    "**2.2.1.3: Compute ELBO of 64 samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Pe-W5XaETD7",
    "outputId": "ba5de8d1-fe2d-4594-ca24-983f4859bd23"
   },
   "outputs": [],
   "source": [
    "sample_cnt = 64\n",
    "samples = np.zeros(shape=(sample_cnt, 784))\n",
    "labels = np.zeros(shape=(sample_cnt, 1))\n",
    "for i in range(sample_cnt):\n",
    "    sample = random.choice(binarized_mnist_train_data)\n",
    "    samples[i] = sample[0].view(1, -1).numpy()\n",
    "    labels[i] = sample[1]\n",
    "\n",
    "prior = testVAE.prior(sample_cnt)\n",
    "samples_tensor = Tensor(samples).to(testVAE.device)\n",
    "posterior = testVAE.encode(samples_tensor)\n",
    "z = testVAE.sample(posterior) # Random sampling\n",
    "reconstruction = testVAE.decode(z)\n",
    "elbo = testVAE.elbo(prior, posterior, reconstruction, samples_tensor, z) \n",
    "\n",
    "# 'float64' required because 'stdev' chokes on 'float32' which is the default type when detaching from GPU\n",
    "elbo_ary = elbo.cpu().detach().numpy().astype('float64')\n",
    "elbo_stddev = statistics.stdev(elbo_ary)\n",
    "elbo_mean = statistics.mean(elbo_ary)\n",
    "print(\"ELBO on %d train data: %.1f +/-%.1f\" % (sample_cnt, elbo_mean,elbo_stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2.3: Training the network**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#binarized_mnist_test_loader = DataLoader(binarized_mnist_test_data, batch_size = 64)\n",
    "trainer = VAE_Trainer(testVAE, binarized_mnist_train_loader_unlabelled, binarized_mnist_test_loader)\n",
    "\n",
    "testVAE_fn = \"./M1_119ls_base_200ep.pt\"\n",
    "if os.path.isfile(testVAE_fn):\n",
    "    testVAE.load_state_dict(torch.load(testVAE_fn))\n",
    "    print(\"Loaded testVAE model from %s\" % testVAE_fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    epochs = 200\n",
    "    for i in range(epochs):\n",
    "        print(\"Training epoch \", i)\n",
    "        trainer.train()\n",
    "        print(\"Testing epoch \", i)\n",
    "        trainer.test()\n",
    "    torch.save(testVAE.state_dict(), testVAE_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2.4: Generating samples from trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testVAE.cpu()\n",
    "#testVAE.cuda()\n",
    "testVAE.eval()\n",
    "\n",
    "prior = testVAE.prior(64)\n",
    "prior_sample = testVAE.sample(prior)\n",
    "decoded_prior_sample = testVAE.decode(prior_sample)\n",
    "sampled_decode_content = decoded_prior_sample.sample().view(64, 28, 28)\n",
    "\n",
    "sampled_decode_content = sampled_decode_content.cpu()\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Pe-W5XaETD7",
    "outputId": "ba5de8d1-fe2d-4594-ca24-983f4859bd23"
   },
   "outputs": [],
   "source": [
    "sample_cnt = binarized_mnist_test_data.data.shape[0]\n",
    "#sample_cnt = 100\n",
    "samples_tensor = torch.empty(sample_cnt,28,28)\n",
    "for idx in range(samples_tensor.shape[0]):\n",
    "    samples_tensor[idx] = binarized_mnist_test_data[idx][0]\n",
    "\n",
    "prior = testVAE.prior(sample_cnt)\n",
    "samples_tensor = samples_tensor.view(sample_cnt,-1).to(testVAE.device)\n",
    "samples_tensor.shape\n",
    "posterior = testVAE.encode(samples_tensor)\n",
    "z = testVAE.sample(posterior)\n",
    "reconstruction = testVAE.decode(z)\n",
    "elbo = testVAE.elbo(prior, posterior, reconstruction, samples_tensor, z) \n",
    "\n",
    "# 'float64' required because 'stdev' chokes on 'float32' which is the default type when detaching from GPU\n",
    "elbo_ary = elbo.cpu().detach().numpy().astype('float64')\n",
    "elbo_stddev = statistics.stdev(elbo_ary)\n",
    "elbo_mean = statistics.mean(elbo_ary)\n",
    "print(\"ELBO on %d test data: %.1f +/-%.1f\" % (sample_cnt, elbo_mean,elbo_stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1: Extracting 10 samples per class for classification training**\n",
    "\n",
    "**ToDo:** Consider more elegant solution for classification_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import functools\n",
    "\n",
    "def classification_sampler(labels):\n",
    "    indices = []\n",
    "    for i in range(10):\n",
    "        #(tmp_indices,) = np.where(functools.reduce(lambda x, y: x | y, [labels.numpy() == i]))\n",
    "        tmp_indices = np.where(labels.numpy() == i)[0]\n",
    "        indices.append(random.choices(tmp_indices, k=10))\n",
    "    indices = torch.Tensor(indices)\n",
    "    indices = indices.view(1, -1).squeeze().int()\n",
    "    return SubsetRandomSampler(indices)\n",
    "    \n",
    "classification_loader = DataLoader(binarized_mnist_train_data, batch_size=25,\n",
    "                                   sampler=classification_sampler(binarized_mnist_train_data.train_labels))\n",
    "# Accuracy of Test Accuracy estimates based on batch_size\n",
    "#  10k: baseline\n",
    "# 2000: 0.5% 0.9% 1.6%\n",
    "# 5000: 0.2% 0.9% 1.2%\n",
    "# Adding 2.5 sec by using all test data instead of just 1000. Worth the price.\n",
    "classification_loader_test = DataLoader(binarized_mnist_test_data, shuffle=True, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check that the same 100 pictures are printed, and only permutated. Evaluate this cell a couple of times.\n",
    "for images, labels in classification_loader:\n",
    "    fig, axs = plt.subplots(1, 25, figsize=(20, 25), squeeze=False)\n",
    "    for i,ax in enumerate(axs.flat):\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "        ax.axis('off') \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.2: Training classifier on latent representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classification model\n",
    "\n",
    "class LatentClassifier(nn.Module):\n",
    "    def __init__(self, latent_features:int) -> None:\n",
    "        super(LatentClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(nn.BatchNorm1d(latent_features*2),    # MAGIC! raises accurcay from 50% to 75%\n",
    "                                   nn.Linear(in_features=latent_features*2, out_features=10), \n",
    "                                   nn.Sigmoid(),  # Initial network used ReLU in output layer, however this was prone to give\n",
    "                                                  # dead outputs, eg. classifier would often train so some classes would \n",
    "                                                  # never be guessed\n",
    "                                   nn.Dropout(p=0.5)        # raises accuracy from 75% to 83%\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class builds a M1 classifier. Output is logits tensor. UNDER CONSTRUCTION.\n",
    "class M1Classifier(nn.Module):\n",
    "    def __init__(self, VAE: nn.Module, LatentClassifier: nn.Module) -> None:\n",
    "        super(M1Classifier, self).__init__()\n",
    "        self.VAE = VAE\n",
    "        self.LatentClassifier = LatentClassifier\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test_eval(cnt, epochs, num_of_evals):\n",
    "    # Used for doing occasional print of test evaluation data.\n",
    "    # Return true 'num_of_evals' times when running range(epochs) training\n",
    "    # Will also trigger at start and end\n",
    "    modulu = math.ceil(epochs/(num_of_evals-1))\n",
    "    return cnt==0 or cnt==epochs-1 or cnt % modulu == modulu-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "testVAE.eval()\n",
    "\n",
    "testLC = LatentClassifier(5)\n",
    "testLC.to(testVAE.device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(testLC.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(testLC.parameters(), lr=0.005)\n",
    "\n",
    "epochs = 200\n",
    "images_test, labels_test = next(iter(classification_loader_test))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    testLC.train()\n",
    "    for images, labels in classification_loader:\n",
    "        images = images.to(testVAE.device)\n",
    "        labels = labels.to(testVAE.device)\n",
    "        outputs = testVAE(images)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1).to(testVAE.device)\n",
    "        optimizer.zero_grad()\n",
    "        classifications = testLC(classifier_input).to(testVAE.device)\n",
    "        loss = criterion(classifications, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluating\n",
    "    if do_test_eval(epoch,epochs,10):\n",
    "        testLC.eval()\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        outputs = testVAE(images_test)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        classifications = testLC(classifier_input)\n",
    "        preds = torch.max(classifications, 1)[1]\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "        accuracy = confuse_matrix_accuracy(confuse_matrix)\n",
    "        print(\"Epoch %3d, train loss %.3f, test accuracy: %.3f\" % (epoch, loss.item(), accuracy))\n",
    "print()\n",
    "print(confuse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue training with x10 reduced 'lr' (learning rate)\n",
    "classification_loader = DataLoader(binarized_mnist_train_data, batch_size=100,\n",
    "                                   sampler=classification_sampler(binarized_mnist_train_data.train_labels))\n",
    "optimizer = optim.Adam(testLC.parameters(), lr=0.0005)\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    testLC.train()\n",
    "    for images, labels in classification_loader:\n",
    "        images = images.to(testVAE.device)\n",
    "        labels = labels.to(testVAE.device)\n",
    "        outputs = testVAE(images)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1).to(testVAE.device)\n",
    "        optimizer.zero_grad()\n",
    "        classifications = testLC(classifier_input).to(testVAE.device)\n",
    "        loss = criterion(classifications, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluating\n",
    "    if do_test_eval(epoch,epochs,10):\n",
    "        testLC.eval()\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        outputs = testVAE(images_test)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        classifications = testLC(classifier_input)\n",
    "        preds = torch.max(classifications, 1)[1]\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "        accuracy = confuse_matrix_accuracy(confuse_matrix)\n",
    "        print(\"Epoch %3d, train loss %.3f, test accuracy: %.3f\" % (epoch, loss.item(), accuracy))\n",
    "print()\n",
    "print(confuse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.3: Classifying MNIST using simple FFNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: training results are noise, rerunning training can give from 64% to 69%. Thus at least 3 restarts must be done to determine is a change was beneficial. With only single-layer FFNN I have difficulty getting above 69%. The dropout layer on the output improves results from 65% to 69%. This is surprising for me, because in the output layer each node is necessary, because it is needed to identify one digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4: M2 implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: torch.Size,\n",
    "                 latent_features: int,\n",
    "                 classes: int, \n",
    "                 hidden_layers_preclass: [], \n",
    "                 hidden_layers_postclass: [], \n",
    "                 hidden_layers_classification: [],\n",
    "                 hidden_layers_decoder: []):\n",
    "        super(M2_VAE, self).__init__()\n",
    "        \n",
    "        # Core params\n",
    "        self.input_shape = input_shape\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        self.register_buffer('classification_prior_params', torch.full(torch.Size([1, classes]), 1 / classes))\n",
    "        self.classes = classes\n",
    "        # Having epochs here makes it possible to continue training, with correct epochs counting\n",
    "        self.epochs = 0\n",
    "        \n",
    "        # Cuda enabling\n",
    "        if torch.cuda.is_available():\n",
    "            self.use_cuda = True\n",
    "            self.device = \"cuda:0\"\n",
    "        else:\n",
    "            self.use_cuda = False\n",
    "            self.device = \"cpu\"\n",
    "        \n",
    "        # Classifier construction\n",
    "        classifier_shape = [self.observation_features]\n",
    "        classifier_shape.extend(hidden_layers_classification)\n",
    "        classifier_shape.append(classes)\n",
    "        self.classifier = FF_NetworkConstructor(layers = classifier_shape,\n",
    "                                                pre_batchnorm = False,\n",
    "                                                hidden_batchnorm = True,\n",
    "                                                hidden_activation = nn.ReLU(),\n",
    "                                                final_activation = None)\n",
    "        \n",
    "        # Pre-classification network construction\n",
    "        preclass_shape = [self.observation_features]\n",
    "        preclass_shape.extend(hidden_layers_preclass)\n",
    "        self.preclass_encoder = FF_NetworkConstructor(layers = preclass_shape,\n",
    "                                                      pre_batchnorm = False,\n",
    "                                                      hidden_batchnorm = True,\n",
    "                                                      hidden_activation = nn.ReLU(),\n",
    "                                                      final_activation = nn.ReLU())\n",
    "        \n",
    "        # Post-classification network construction\n",
    "        postclass_shape = [hidden_layers_preclass[-1] + classes]\n",
    "        postclass_shape.extend(hidden_layers_postclass)\n",
    "        postclass_shape.append(latent_features * 2)\n",
    "        self.postclass_encoder = FF_NetworkConstructor(layers = postclass_shape,\n",
    "                                                       pre_batchnorm = False,\n",
    "                                                       hidden_batchnorm = True,\n",
    "                                                       hidden_activation = nn.ReLU(),\n",
    "                                                       final_activation = None)\n",
    "        \n",
    "        # Decoder construction\n",
    "        decoder_shape = [latent_features + classes]\n",
    "        decoder_shape.extend(hidden_layers_decoder)\n",
    "        decoder_shape.append(self.observation_features)\n",
    "        self.decoder = FF_NetworkConstructor(layers = decoder_shape,\n",
    "                                             pre_batchnorm = False,\n",
    "                                             hidden_batchnorm = True,\n",
    "                                             hidden_activation = nn.ReLU(),\n",
    "                                             final_activation = None)\n",
    "        \n",
    "        # Move networks to cuda if available\n",
    "        if self.use_cuda:\n",
    "            self.classifier.cuda()\n",
    "            self.preclass_encoder.cuda()\n",
    "            self.postclass_encoder.cuda()\n",
    "            self.decoder.cuda()\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        for layers in self.children():\n",
    "            for layer in layers:\n",
    "                if hasattr(layer, 'reset_parameters'):\n",
    "                    layer.reset_parameters()\n",
    "        self.epochs = 0\n",
    "\n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        result = ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        result.mu = result.mu.to(self.device)\n",
    "        result.sigma = result.sigma.to(self.device)\n",
    "        return result\n",
    "    \n",
    "    def classification_prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_classification_prior_params = self.classification_prior_params.expand(batch_size, \n",
    "                                                                                    *self.classification_prior_params.shape[-1:])\n",
    "        result = Categorical(probs = local_classification_prior_params)\n",
    "        return result\n",
    "    \n",
    "    def classification_posterior(self, x: Tensor) -> Distribution:\n",
    "        result = self.classifier(x)\n",
    "        result = result.view(-1, self.classes)\n",
    "        result = Categorical(logits = result)\n",
    "        return result\n",
    "    \n",
    "    def classification_entropy(self, qy: Tensor) -> float:\n",
    "        qy = qy * torch.log(qy)\n",
    "        return -qy.sum(1)\n",
    "        \n",
    "    def encode(self, x: Tensor, y: Tensor = None) -> Tensor:\n",
    "        # Classify if no classification is provided\n",
    "        if y is None:\n",
    "            y = self.classifier(x)\n",
    "        # Encode input\n",
    "        result = self.preclass_encoder(x)\n",
    "        result = torch.cat((result, y), 1)\n",
    "        result = self.postclass_encoder(result)\n",
    "        mu, log_sigma =  result.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def decode(self, z: Tensor, y: Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(torch.cat((z, y), 1))\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits = px_logits)\n",
    "    \n",
    "    def onehot(self, y: int):\n",
    "        result = torch.zeros(y.shape[0], self.classes).to(self.device)\n",
    "        for i in range(len(y)):\n",
    "            result[i][y[i]] = 1\n",
    "        return result\n",
    "    \n",
    "    def loss(self,\n",
    "             px: Distribution, \n",
    "             py: Distribution, \n",
    "             pz: Distribution, \n",
    "             qy: Distribution, \n",
    "             qz: Distribution, \n",
    "             x: Tensor,\n",
    "             y: int, \n",
    "             z: Tensor,\n",
    "             alpha: float,\n",
    "             debug: bool = False) -> float:\n",
    "        x = x.to(self.device)\n",
    "        z = z.to(self.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        py_logprob = py.logits.to(self.device)\n",
    "        \n",
    "        # If labels are not provided, sample from classification posterior\n",
    "        if y is None:\n",
    "            if True:\n",
    "                # Paralel calcution giving 40% speedup compared to serial version below.\n",
    "                x2 = x.repeat(10,1)\n",
    "                y2 = torch.Tensor(0)\n",
    "                for i in range(10):\n",
    "                    y2 = torch.cat( (y2, torch.Tensor([i]).expand(x.shape[0])))\n",
    "                y2 = y2.to(self.device)\n",
    "                outputs = self.forward(x2, y2)\n",
    "                px_logprob = outputs['px'].log_prob(x2.view(10*x.shape[0],-1)).sum(dim=1).view(-1,10)\n",
    "                qz_logprob = outputs['qz'].log_prob(outputs['z']).sum(dim=1).view(-1, 10)\n",
    "                pz_logprob = outputs['pz'].log_prob(outputs['z']).sum(dim=1).view(-1, 10)\n",
    "            else:\n",
    "                # Original serial calculation. Kept as fall-back until parallel version has been more tested\n",
    "                px_logprob = torch.Tensor(0).to(self.device)\n",
    "                qz_logprob = torch.Tensor(0).to(self.device)\n",
    "                pz_logprob = torch.Tensor(0).to(self.device)\n",
    "                for i in range(10):\n",
    "                    _y = torch.Tensor([i]).expand(x.shape[0])\n",
    "                    outputs = self.forward(x, _y)\n",
    "                    px_logprob = torch.cat((px_logprob, outputs['px'].log_prob(x).sum(dim = 1).view(-1, 1)), 1)\n",
    "                    qz_logprob = torch.cat((qz_logprob, outputs['qz'].log_prob(outputs['z']).sum(dim = 1).view(-1, 1)), 1)\n",
    "                    pz_logprob = torch.cat((pz_logprob, outputs['pz'].log_prob(outputs['z']).sum(dim = 1).view(-1, 1)), 1)\n",
    "            L = -(px_logprob + py_logprob + pz_logprob - qz_logprob)\n",
    "            U = -(torch.mul(qy.probs, -L).sum(1) + self.classification_entropy(qy.probs))\n",
    "            J = U\n",
    "            return J\n",
    "        \n",
    "        else:\n",
    "            y = y.to(self.device)\n",
    "            y = y.view(-1, 1)\n",
    "            px_logprob = px.log_prob(x).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            qz_logprob = qz.log_prob(z).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            pz_logprob = pz.log_prob(z).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            L = -(px_logprob + py_logprob + pz_logprob - qz_logprob)\n",
    "            J = L.gather(1, y)\n",
    "            J_alpha = J - (alpha * qy.logits.gather(1, y))\n",
    "            return J_alpha\n",
    "    \n",
    "    def forward(self, x: Tensor, y: int = None, debug: bool = False) -> Dict[str, Any]:\n",
    "        x = x.to(self.device) # Move to cuda if applicable\n",
    "        x = x.view(x.size(0), -1) # Flatten image input\n",
    "        qy = self.classification_posterior(x) # Classification posterior q(y|x)\n",
    "        py = self.classification_prior(batch_size = x.size(0)) # Classification prior p(y)\n",
    "        pz = self.prior(batch_size=x.size(0)) # Prior p(z)\n",
    "        if y is None: # If labels are not provided, sample from classification posterior\n",
    "            try:\n",
    "                y = qy.sample()\n",
    "            except:\n",
    "                print(self.classifier(x))\n",
    "                raise Exception(\"QY sample error\")\n",
    "        \n",
    "        y = y.to(self.device)\n",
    "        y = y.int()\n",
    "        y = self.onehot(y)\n",
    "        qz = self.encode(x, y) # Approximate posterior q(z|x, y)\n",
    "        z = qz.rsample() # Sample the posterior\n",
    "        px = self.decode(z, y) # Reconstruction p(x|z, y) = B(x | g(z, y))\n",
    "        \n",
    "        return {'px': px, 'py': py, 'pz': pz, 'qy': qy, 'qz': qz, 'z': z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE_Trainer:\n",
    "    def __init__(self,\n",
    "                 network:M2_VAE              = None,\n",
    "                 train_labelled:DataLoader   = None,\n",
    "                 train_unlabelled:DataLoader = None,\n",
    "                 test:DataLoader             = None,\n",
    "                 labelled_passes:int         = 1,\n",
    "                 alpha:float                 = 0.1,\n",
    "                 verbose:int                 = 0):\n",
    "        self.model            = network          if network          != None else TestM2\n",
    "        self.train_labelled   = train_labelled   if train_labelled   != None else binarized_mnist_train_loader_labelled\n",
    "        self.train_unlabelled = train_unlabelled if train_unlabelled != None else binarized_mnist_train_loader_unlabelled\n",
    "        self.test_data        = test             if test             != None else binarized_mnist_test_loader\n",
    "        self.alpha = alpha\n",
    "        self.training_data = defaultdict(list)\n",
    "        self.validation_data = defaultdict(list)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.labelled_passes = labelled_passes\n",
    "        self.unlbl_bcnt = 0\n",
    "        self.lbl_bcnt = 0\n",
    "        self.tst_bcnt = 0\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        if self.train_unlabelled is not None:\n",
    "            for images, labels in self.train_unlabelled:\n",
    "                self.unlbl_bcnt += 1\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images, None)\n",
    "                loss = self.model.loss(outputs['px'], \n",
    "                                       outputs['py'], \n",
    "                                       outputs['pz'], \n",
    "                                       outputs['qy'], \n",
    "                                       outputs['qz'],\n",
    "                                       images, \n",
    "                                       None,\n",
    "                                       outputs['z'],\n",
    "                                       self.alpha).mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        for i in range(self.labelled_passes):\n",
    "            for images, labels in self.train_labelled:\n",
    "                self.lbl_bcnt += 1\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images, labels)\n",
    "                loss = self.model.loss(outputs['px'], \n",
    "                                       outputs['py'], \n",
    "                                       outputs['pz'], \n",
    "                                       outputs['qy'], \n",
    "                                       outputs['qz'],\n",
    "                                       images, \n",
    "                                       labels,\n",
    "                                       outputs['z'],\n",
    "                                       self.alpha).mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        self.model.epochs += 1\n",
    "    \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        i = 0\n",
    "        epoch_data = defaultdict(list)\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        for images, labels in self.test_data:\n",
    "            self.tst_bcnt += 1\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha).mean()\n",
    "            epoch_data['loss'] += [loss.item()]\n",
    "\n",
    "            classifications = self.model.classifier(images.view(-1,28*28).to(self.model.device))\n",
    "            preds = torch.argmax(classifications,1)\n",
    "            confuse_matrix_update(preds, labels, confuse_matrix)\n",
    "\n",
    "        for k, v in epoch_data.items():\n",
    "            self.validation_data[k] += [np.mean(v)]\n",
    "        self.validation_data['class_accu'] += [confuse_matrix_accuracy(confuse_matrix)]\n",
    "\n",
    "        print(\"epoch=%d  test_loss=%.2f  class_accu=%.3f\" % (self.model.epochs, \n",
    "                                                             self.validation_data['loss'][-1], \n",
    "                                                             self.validation_data['class_accu'][-1]))\n",
    "        print(\"         unlbl_bcnt=%d, lbl_bcnt=%d, tst_bcnt=%d\" % (self.unlbl_bcnt,\n",
    "                                                                    self.lbl_bcnt,\n",
    "                                                                    self.tst_bcnt)) if self.verbose > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "#print(TestM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved models. Enable one of these lines to load model\n",
    "fn = \"M2_axbr1_0p76_10ep.pt\"    # 2020-12-04 11:00, 100 labelled, 0 unlabelled, 10epochs*10passes, 56 sec training\n",
    "fn = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_setup(labelled_size=100)                     # mixed, unlabelled will be 50k - 100\n",
    "loader_setup(labelled_size=100, unlabelled_size=0)  # skip unlabelled training\n",
    "#loader_setup(labelled_size=0, unlabelled_size=1000, test_size=10)  # debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestM2.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "trainer = M2_VAE_Trainer(labelled_passes = 10)\n",
    "\n",
    "epochs = 10\n",
    "if fn != \"\" and os.path.isfile(fn):\n",
    "    TestM2.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execution speed measurements\n",
    "# measure    calc.   \n",
    "# sec        sec   \n",
    "#  8.4       4.2    10k test\n",
    "# 44         36     10k unlbl train\n",
    "# 80,76,75    6.8   10k lbl train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"\"   # fill-out to save model you trained above, and document the file-name is the cell higher up\n",
    "if fn != \"\":\n",
    "    torch.save(TestM2.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confuse_matrix(TestM2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STYLE TRANSFER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestM2.eval()\n",
    "a = random.choices(binarized_mnist_train_data,k=10)\n",
    "b = [x[0] for x in a]\n",
    "img = torch.stack(b)\n",
    "b = [x[1] for x in a]\n",
    "lbl = torch.Tensor(b)\n",
    "fig, axs = plt.subplots(10, 11, figsize=(10, 10), squeeze=False)\n",
    "\n",
    "outputs = TestM2(img, lbl)\n",
    "z = outputs['z']\n",
    "\n",
    "for i in range(len(img)):\n",
    "    axs[i, 0].imshow(img[i], cmap='gray')\n",
    "    axs[i, 0].axis('off')\n",
    "    for j in range(10):\n",
    "        image = TestM2.decode(z[i].reshape(1, -1), TestM2.onehot(torch.Tensor([j]).int())).sample().view(28,28).cpu()\n",
    "        axs[i, j + 1].imshow(image, cmap='gray')\n",
    "        axs[i, j + 1].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VAE Eksamen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
