{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEBI-teSY67-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torchvision.datasets import MNIST\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import Bernoulli\n",
    "from typing import Dict, Any\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "import math\n",
    "import os.path\n",
    "from torch.distributions import Categorical\n",
    "# Static random seed\n",
    "np.random.seed(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LAMBDAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert data to Tensor, because the DataLoader iterator refuses to work with PIL image objects.\n",
    "pil2tensor = lambda x: ToTensor()(x).squeeze()   # ToTensor return (64,1,28,28), the squeeze() call removes the 1 dimension\n",
    "\n",
    "# Binarize method for binarized dataset\n",
    "binarize = lambda x: torch.bernoulli(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwTMdXXreBbl"
   },
   "outputs": [],
   "source": [
    "mnist_train_data = MNIST(\"./temp/\", transform=pil2tensor, download=True, train=True)\n",
    "mnist_test_data = MNIST(\"./temp/\", transform=pil2tensor, download=True, train=False)\n",
    "\n",
    "binarized_mnist_train_data = MNIST(\"./temp/\",\n",
    "                                   download=True,\n",
    "                                   train=True,\n",
    "                                   transform=transforms.Compose([pil2tensor,\n",
    "                                                                 binarize]))\n",
    "binarized_mnist_test_data = MNIST(\"./temp/\",\n",
    "                                  download=True,\n",
    "                                  train=False,\n",
    "                                  transform=transforms.Compose([pil2tensor,\n",
    "                                                                binarize]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATALOADERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUESTION: Can we rely on the DataLoader to visit every contained sample over the course \n",
    "# of one epoch when using SubsetRandomSampler? If no, we should change something here...\n",
    "\n",
    "# TODO: labelled data should contain same number of each digit, and set should be reduced from 10k to 100\n",
    "\n",
    "# TODO: consider adding 'shuffle=True' to DataLoader, though unsure how interaction is with \n",
    "#       SubsetRandomSampler\n",
    "\n",
    "# Initialize dataset indices\n",
    "indices_train = list(range(len(binarized_mnist_train_data))) # 60000\n",
    "\n",
    "# Split train into labelled, unlabelled and validation.\n",
    "labelled_size = 10000\n",
    "unlabelled_size = 40000\n",
    "validation_size = 10000\n",
    "\n",
    "# Shuffle dataset\n",
    "np.random.shuffle(indices_train)\n",
    "\n",
    "# Next, split the indices\n",
    "labelled_idx = indices_train[:labelled_size]\n",
    "unlabelled_idx = indices_train[labelled_size:labelled_size + unlabelled_size]\n",
    "validation_idx = indices_train[labelled_size + unlabelled_size:]\n",
    "\n",
    "# Last, generate the dataloaders\n",
    "binarized_mnist_train_loader_labelled = DataLoader(binarized_mnist_train_data, \n",
    "                                                   batch_size = 64, \n",
    "                                                   sampler = SubsetRandomSampler(labelled_idx))\n",
    "binarized_mnist_train_loader_unlabelled = DataLoader(binarized_mnist_train_data, \n",
    "                                                     batch_size = 64, \n",
    "                                                     sampler = SubsetRandomSampler(unlabelled_idx))\n",
    "binarized_mnist_train_loader_validation = DataLoader(binarized_mnist_train_data, \n",
    "                                                     batch_size = 64, \n",
    "                                                     sampler = SubsetRandomSampler(validation_idx))\n",
    "\n",
    "# Do not subdivide Test (this approach might be inappropriate when no intention to subdivide - check for better solution):\n",
    "indices_test = list(range(len(binarized_mnist_test_data))) # 10000\n",
    "binarized_mnist_test_loader = DataLoader(binarized_mnist_train_data, \n",
    "                                         batch_size = 64, \n",
    "                                         sampler = SubsetRandomSampler(indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-binarized dataloader\n",
    "indices_train = list(range(len(mnist_train_data))) # 60000\n",
    "mnist_train_loader = DataLoader(mnist_train_data, \n",
    "                                batch_size = 64, \n",
    "                                sampler = SubsetRandomSampler(indices_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REPARAMETERIZED DIAGONAL GUASSIAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "370tki2E3CBG"
   },
   "outputs": [],
   "source": [
    "# Implement reparameterized diagonal gaussian\n",
    "#from torch.distributions import Distribution\n",
    "\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    def __init__(self, mu: Tensor, log_sigma: Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        return self.mu + self.sigma*self.sample_epsilon()\n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        from torch.distributions import Normal \n",
    "        return  Normal(loc=self.mu, scale=self.sigma).log_prob(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NETWORK CONSTRUCTOR HELPER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FF_NetworkConstructor(layers: [],\n",
    "                          pre_batchnorm: bool,\n",
    "                          hidden_batchnorm: bool,\n",
    "                          hidden_activation,\n",
    "                          final_activation) -> nn.Sequential:\n",
    "    constructor = []\n",
    "    if pre_batchnorm:\n",
    "        constructor.append(nn.BatchNorm1d(num_features = layers[0]))\n",
    "    for i in range(len(layers) - 2):\n",
    "        constructor.append(nn.Linear(in_features = layers[i],\n",
    "                                     out_features = layers[i + 1]))\n",
    "        constructor.append(hidden_activation)\n",
    "        if hidden_batchnorm:\n",
    "            constructor.append(nn.BatchNorm1d(num_features = layers[i + 1]))\n",
    "    \n",
    "    constructor.append(nn.Linear(in_features = layers[-2], out_features = layers[-1]))\n",
    "    if final_activation is not None:\n",
    "        constructor.append(final_activation)\n",
    "    result = nn.Sequential(*constructor)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA ANALYSIS SUPPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse_matrix_update(predictions, labels, confusion_matrix):\n",
    "    # Update 'confusion_matrix' according the the prodictions/labels vectors.\n",
    "    # Confusion_matrix rows are actual labels, and columns predictions. E.g. row 0 \n",
    "    # tells how the classifier predicted '0', (0,0) represents correct predictions, \n",
    "    # (0,1) is how many times a '0' was classified as a '1'\n",
    "    for pre, lbl in zip(predictions, labels):\n",
    "        confusion_matrix[lbl,pre] += 1\n",
    "def confuse_matrix_accuracy(cm):\n",
    "    return 0.0 if cm.sum() == 0 else cm.trace()/cm.sum()\n",
    "if False:\n",
    "    cm = np.zeros((10,10))\n",
    "    pred=torch.tensor([2,9,8,6])\n",
    "    lab =torch.tensor([2,9,8,4])\n",
    "    confuse_matrix_update(pred,lab,cm)\n",
    "    confuse_matrix_update(pred,lab,cm)\n",
    "    print(cm, confuse_matrix_accuracy(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confuse_matrix(VAE, test_loader = binarized_mnist_test_loader):\n",
    "    # print confuse_matrix for 'VAE' which is assumed to have function 'classifier'\n",
    "    # and variable 'device' indicating cpu or cuda.\n",
    "    confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "    for images_test,labels_test in test_loader:\n",
    "        images_test = images_test.to(VAE.device)\n",
    "        classifications = VAE.classifier(images_test.view(-1,28*28))\n",
    "        preds = torch.argmax(classifications,1)\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "    print(confuse_matrix)\n",
    "    print(\"Classifier accuracy: %.3f\" % confuse_matrix_accuracy(confuse_matrix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAE IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF5c_hYM8v-o"
   },
   "outputs": [],
   "source": [
    "# Summarize values per sample\n",
    "def reduce(x: Tensor) -> Tensor:\n",
    "    return x.view(x.size(0), -1).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHWnmyLfrTBF"
   },
   "outputs": [],
   "source": [
    "# Define hidden layer topology - list of sizes of hidden layers\n",
    "encoder_dimensions = [512, 256, 128]\n",
    "decoder_dimensions = [128, 256, 512]\n",
    "apply_per_layer_batchnorm = False\n",
    "\n",
    "# Implement VAE\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_shape:torch.Size, latent_features:int) -> None:\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "\n",
    "        # Core parameters\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        \n",
    "        # Cuda enabling\n",
    "        if torch.cuda.is_available():\n",
    "            self.use_cuda = True\n",
    "            self.device = \"cuda:0\"\n",
    "        else:\n",
    "            self.use_cuda = False\n",
    "            self.device = \"cpu\"\n",
    "        \n",
    "        # Dynamically constructing the encoder network\n",
    "        encoder_constructor = []\n",
    "        encoder_constructor.append(nn.Linear(in_features=self.observation_features, out_features=encoder_dimensions[0]))\n",
    "        encoder_constructor.append(nn.ReLU())\n",
    "        if apply_per_layer_batchnorm:\n",
    "            encoder_constructor.append(nn.BatchNorm1d(num_features=encoder_dimensions[0]))\n",
    "        for i in range(len(encoder_dimensions)-1):\n",
    "            encoder_constructor.append(nn.Linear(in_features=encoder_dimensions[i], out_features=encoder_dimensions[i+1]))\n",
    "            encoder_constructor.append(nn.ReLU())\n",
    "            if apply_per_layer_batchnorm:\n",
    "                encoder_constructor.append(nn.BatchNorm1d(num_features=encoder_dimensions[i+1]))\n",
    "        encoder_constructor.append(nn.Linear(in_features=encoder_dimensions[-1], out_features=2*self.latent_features))\n",
    "        self.encoder = nn.Sequential(*encoder_constructor)\n",
    "\n",
    "        # Dynamically constructing the decoder network\n",
    "        decoder_constructor = []\n",
    "        decoder_constructor.append(nn.Linear(in_features=self.latent_features, out_features=decoder_dimensions[0]))\n",
    "        decoder_constructor.append(nn.ReLU())\n",
    "        if apply_per_layer_batchnorm:\n",
    "            decoder_constructor.append(nn.BatchNorm1d(num_features=decoder_dimensions[0]))\n",
    "        for i in range(len(decoder_dimensions)-1):\n",
    "            decoder_constructor.append(nn.Linear(in_features=decoder_dimensions[i], out_features=decoder_dimensions[i+1]))\n",
    "            decoder_constructor.append(nn.ReLU())\n",
    "            if apply_per_layer_batchnorm:\n",
    "                decoder_constructor.append(nn.BatchNorm1d(num_features=decoder_dimensions[i+1]))\n",
    "        decoder_constructor.append(nn.Linear(in_features=decoder_dimensions[-1], out_features=self.observation_features))\n",
    "        self.decoder = nn.Sequential(*decoder_constructor)\n",
    "        \n",
    "        if self.use_cuda:\n",
    "            self.encoder.cuda()\n",
    "            self.decoder.cuda()\n",
    "    \n",
    "    # Encode input into posterior distribution\n",
    "    def encode(self, x: Tensor) -> Distribution:\n",
    "        h_x = self.encoder(x)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    # Decode latent variables into reconstruction\n",
    "    def decode(self, z: Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(z)\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits=px_logits)\n",
    "    \n",
    "    # Get the prior distribution\n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    # Sample from a provided distribution\n",
    "    def sample(self, distribution: ReparameterizedDiagonalGaussian) -> Tensor:\n",
    "        return distribution.rsample()\n",
    "    \n",
    "    # Compute the ELBO\n",
    "    def elbo(self, prior: Distribution, posterior: Distribution, reconstruction: Distribution, x: Tensor, z: Tensor) -> float:\n",
    "        tst = reconstruction.sample()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        log_px = reduce(reconstruction.log_prob(x))\n",
    "        log_pz = reduce(prior.log_prob(z))\n",
    "        log_qz = reduce(posterior.log_prob(z))\n",
    "        kl = log_qz - log_pz\n",
    "        elbo = log_px - kl\n",
    "        return elbo\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Dict[str, Any]:\n",
    "        # flatten the input\n",
    "        x = x.to(self.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.encode(x)\n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        z = qz.rsample()\n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.decode(z)\n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAE TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "class VAE_Trainer:\n",
    "    def __init__(self, network: VariationalAutoEncoder, train: DataLoader, test: DataLoader):\n",
    "        self.VAE = network\n",
    "        self.train_data = train\n",
    "        self.test_data = test\n",
    "        self.optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "    \n",
    "    def train(self):\n",
    "        self.VAE.train()\n",
    "        for images, labels in self.train_data:\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.VAE(images)\n",
    "            loss = -self.VAE.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def test(self):\n",
    "        self.VAE.eval()\n",
    "        losses = []\n",
    "        i = 0\n",
    "        for images, labels in self.test_data:\n",
    "            outputs = self.VAE(images)\n",
    "            elbos = self.VAE.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).cpu().detach().numpy()\n",
    "            losses = np.append(losses, elbos)\n",
    "        loss = -np.mean(losses)\n",
    "        print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2 VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily moved to end of notebook while development and tests are ongoing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily moved to end of notebook while development and tests are ongoing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxXpiIwXGYvY"
   },
   "source": [
    "**SUBTASK 2.1.2: Plot 8x8 random samples from MNIST data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "ixxaXCQCO_dB",
    "outputId": "95e6471d-aa7d-460d-e80a-e9e0b9080403"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(mnist_train_loader))\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(\"%s\" % (labels[i].item()))\n",
    "    ax.axis('off')\n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLIEWEXOoOpt"
   },
   "source": [
    "**SUBTASK 2.1.4: Plot binarized MNIST samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "_Qf9sLMqhyaQ",
    "outputId": "9701d2a4-a4fc-4f79-c854-0ed0fde5995c"
   },
   "outputs": [],
   "source": [
    "# Plot same image a couple of times to verify we are doing statistical sampling every time the image is drawn\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3), squeeze=False)\n",
    "for ax in axs.flat:\n",
    "    sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "    assert torch.max(sample) == 1.0\n",
    "    assert torch.min(sample) == 0.0\n",
    "    ax.imshow(sample, cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "-9Jj6BslTiPt",
    "outputId": "2c88f850-a28e-4b62-8280-10c5e8daa311"
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(binarized_mnist_train_loader_labelled))\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(\"%s\" % (labels[i].item()))\n",
    "    ax.axis('off')\n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xht6E_a-Mee"
   },
   "source": [
    "**SUBTASK 2.2.1.2: Print samples from untrained VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxhZisS33nwM",
    "outputId": "e40f6ce3-9970-43db-9b5f-8cea8c7e372e"
   },
   "outputs": [],
   "source": [
    "# Instantiate a VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(0)[0]\n",
    "testVAE = VariationalAutoEncoder(sample.flatten().shape, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Decoding sample from prior\n",
    "testVAE.cpu()\n",
    "testVAE.eval()\n",
    "\n",
    "prior = testVAE.prior(64)\n",
    "prior_sample = testVAE.sample(prior)\n",
    "decoded_prior_sample = testVAE.decode(prior_sample)\n",
    "sampled_decode_content = decoded_prior_sample.sample().view(64, 28, 28)\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "cwWZmv9Y9Urq",
    "outputId": "a4b073a4-af3f-4872-fc57-3eb7afa0f798"
   },
   "outputs": [],
   "source": [
    "# Method 2: Reconstruction of input from binarized MNIST\n",
    "a = random.choices(binarized_mnist_train_data,k=64)\n",
    "b = [x[0] for x in a]\n",
    "img = torch.stack(b)\n",
    "sampled_decode_content = testVAE(img)['px'].sample().view(-1,28,28)\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgglyZU6FNZl"
   },
   "source": [
    "**2.2.1.3: Compute ELBO of 64 samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Pe-W5XaETD7",
    "outputId": "ba5de8d1-fe2d-4594-ca24-983f4859bd23"
   },
   "outputs": [],
   "source": [
    "sample_cnt = 64\n",
    "samples = np.zeros(shape=(sample_cnt, 784))\n",
    "labels = np.zeros(shape=(sample_cnt, 1))\n",
    "for i in range(sample_cnt):\n",
    "    sample = random.choice(binarized_mnist_train_data)\n",
    "    samples[i] = sample[0].view(1, -1).numpy()\n",
    "    labels[i] = sample[1]\n",
    "\n",
    "prior = testVAE.prior(sample_cnt)\n",
    "samples_tensor = Tensor(samples)\n",
    "posterior = testVAE.encode(samples_tensor)\n",
    "z = testVAE.sample(posterior) # Random sampling\n",
    "reconstruction = testVAE.decode(z)\n",
    "elbo = testVAE.elbo(prior, posterior, reconstruction, samples_tensor, z) \n",
    "\n",
    "# 'float64' required because 'stdev' chokes on 'float32' which is the default type when detaching from GPU\n",
    "elbo_ary = elbo.detach().numpy().astype('float64')\n",
    "elbo_stddev = statistics.stdev(elbo_ary)\n",
    "elbo_mean = statistics.mean(elbo_ary)\n",
    "print(\"ELBO on %d train data: %.1f +/-%.1f\" % (sample_cnt, elbo_mean,elbo_stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2.3: Training the network**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#binarized_mnist_test_loader = DataLoader(binarized_mnist_test_data, batch_size = 64)\n",
    "trainer = VAE_Trainer(testVAE, binarized_mnist_train_loader_unlabelled, binarized_mnist_test_loader)\n",
    "\n",
    "testVAE_fn = \"./M1_119ls_base_200ep.pt\"\n",
    "if False and os.path.isfile(testVAE_fn):\n",
    "    testVAE.load_state_dict(torch.load(testVAE_fn))\n",
    "    print(\"Loaded testVAE model from %s\" % testVAE_fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    epochs = 200\n",
    "    for i in range(epochs):\n",
    "        print(\"Training epoch \", i)\n",
    "        trainer.train()\n",
    "        print(\"Testing epoch \", i)\n",
    "        trainer.test()\n",
    "    torch.save(testVAE.state_dict(), testVAE_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2.4: Generating samples from trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVAE.cpu()\n",
    "testVAE.eval()\n",
    "\n",
    "prior = testVAE.prior(64)\n",
    "prior_sample = testVAE.sample(prior)\n",
    "decoded_prior_sample = testVAE.decode(prior_sample)\n",
    "sampled_decode_content = decoded_prior_sample.sample().view(64, 28, 28)\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Pe-W5XaETD7",
    "outputId": "ba5de8d1-fe2d-4594-ca24-983f4859bd23"
   },
   "outputs": [],
   "source": [
    "sample_cnt = binarized_mnist_test_data.data.shape[0]\n",
    "#sample_cnt = 100\n",
    "samples_tensor = torch.empty(sample_cnt,28,28)\n",
    "for idx in range(samples_tensor.shape[0]):\n",
    "    samples_tensor[idx] = binarized_mnist_test_data[idx][0]\n",
    "\n",
    "prior = testVAE.prior(sample_cnt)\n",
    "samples_tensor = samples_tensor.view(sample_cnt,-1)\n",
    "samples_tensor.shape\n",
    "posterior = testVAE.encode(samples_tensor)\n",
    "z = testVAE.sample(posterior)\n",
    "reconstruction = testVAE.decode(z)\n",
    "elbo = testVAE.elbo(prior, posterior, reconstruction, samples_tensor, z) \n",
    "\n",
    "# 'float64' required because 'stdev' chokes on 'float32' which is the default type when detaching from GPU\n",
    "elbo_ary = elbo.detach().numpy().astype('float64')\n",
    "elbo_stddev = statistics.stdev(elbo_ary)\n",
    "elbo_mean = statistics.mean(elbo_ary)\n",
    "print(\"ELBO on %d test data: %.1f +/-%.1f\" % (sample_cnt, elbo_mean,elbo_stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1: Extracting 10 samples per class for classification training**\n",
    "\n",
    "**ToDo:** Consider more elegant solution for classification_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import functools\n",
    "\n",
    "def classification_sampler(labels):\n",
    "    indices = []\n",
    "    for i in range(10):\n",
    "        #(tmp_indices,) = np.where(functools.reduce(lambda x, y: x | y, [labels.numpy() == i]))\n",
    "        tmp_indices = np.where(labels.numpy() == i)[0]\n",
    "        indices.append(random.choices(tmp_indices, k=10))\n",
    "    indices = torch.Tensor(indices)\n",
    "    indices = indices.view(1, -1).squeeze().int()\n",
    "    return SubsetRandomSampler(indices)\n",
    "    \n",
    "classification_loader = DataLoader(binarized_mnist_train_data, batch_size=25,\n",
    "                                   sampler=classification_sampler(binarized_mnist_train_data.train_labels))\n",
    "# Accuracy of Test Accuracy estimates based on batch_size\n",
    "#  10k: baseline\n",
    "# 2000: 0.5% 0.9% 1.6%\n",
    "# 5000: 0.2% 0.9% 1.2%\n",
    "# Adding 2.5 sec by using all test data instead of just 1000. Worth the price.\n",
    "classification_loader_test = DataLoader(binarized_mnist_test_data, shuffle=True, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check that the same 100 pictures are printed, and only permutated. Evaluate this cell a couple of times.\n",
    "for images, labels in classification_loader:\n",
    "    fig, axs = plt.subplots(1, 25, figsize=(20, 25), squeeze=False)\n",
    "    for i,ax in enumerate(axs.flat):\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "        ax.axis('off') \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.2: Training classifier on latent representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classification model\n",
    "\n",
    "class LatentClassifier(nn.Module):\n",
    "    def __init__(self, latent_features:int) -> None:\n",
    "        super(LatentClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(nn.BatchNorm1d(latent_features*2),    # MAGIC! raises accurcay from 50% to 75%\n",
    "                                   nn.Linear(in_features=latent_features*2, out_features=10), \n",
    "                                   nn.Sigmoid(),  # Initial network used ReLU in output layer, however this was prone to give\n",
    "                                                  # dead outputs, eg. classifier would often train so some classes would \n",
    "                                                  # never be guessed\n",
    "                                   nn.Dropout(p=0.5)        # raises accuracy from 75% to 83%\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class builds a M1 classifier. Output is logits tensor. UNDER CONSTRUCTION.\n",
    "class M1Classifier(nn.Module):\n",
    "    def __init__(self, VAE: nn.Module, LatentClassifier: nn.Module) -> None:\n",
    "        super(M1Classifier, self).__init__()\n",
    "        self.VAE = VAE\n",
    "        self.LatentClassifier = LatentClassifier\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test_eval(cnt, epochs, num_of_evals):\n",
    "    # Used for doing occasional print of test evaluation data.\n",
    "    # Return true 'num_of_evals' times when running range(epochs) training\n",
    "    # Will also trigger at start and end\n",
    "    modulu = math.ceil(epochs/(num_of_evals-1))\n",
    "    return cnt==0 or cnt==epochs-1 or cnt % modulu == modulu-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "testVAE.eval()\n",
    "\n",
    "testLC = LatentClassifier(5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(testLC.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(testLC.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "images_test, labels_test = next(iter(classification_loader_test))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    testLC.train()\n",
    "    for images, labels in classification_loader:\n",
    "        outputs = testVAE(images)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        optimizer.zero_grad()\n",
    "        classifications = testLC(classifier_input)\n",
    "        loss = criterion(classifications, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluating\n",
    "    if do_test_eval(epoch,epochs,10):\n",
    "        testLC.eval()\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        outputs = testVAE(images_test)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        classifications = testLC(classifier_input)\n",
    "        preds = torch.max(classifications, 1)[1]\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "        accuracy = confuse_matrix_accuracy(confuse_matrix)\n",
    "        print(\"Epoch %3d, train loss %.3f, test accuracy: %.3f\" % (epoch, loss.item(), accuracy))\n",
    "print()\n",
    "print(confuse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_loader = DataLoader(binarized_mnist_train_data, batch_size=100,\n",
    "                                   sampler=classification_sampler(binarized_mnist_train_data.train_labels))\n",
    "optimizer = optim.Adam(testLC.parameters(), lr=0.0005)\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    testLC.train()\n",
    "    for images, labels in classification_loader:\n",
    "        outputs = testVAE(images)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        optimizer.zero_grad()\n",
    "        classifications = testLC(classifier_input)\n",
    "        loss = criterion(classifications, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluating\n",
    "    if do_test_eval(epoch,epochs,10):\n",
    "        testLC.eval()\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        outputs = testVAE(images_test)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        classifications = testLC(classifier_input)\n",
    "        preds = torch.max(classifications, 1)[1]\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "        accuracy = confuse_matrix_accuracy(confuse_matrix)\n",
    "        print(\"Epoch %3d, train loss %.3f, test accuracy: %.3f\" % (epoch, loss.item(), accuracy))\n",
    "print()\n",
    "print(confuse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells notes:\n",
    "Initial results showed large accuracy variation, varying from 0.40 to 0.73 accuracy. Confusion matrix revealed that some numbers were never chosen. E.g. below where classifier never outputs a '9' classification.\n",
    "<code>\n",
    "[[464   0  12   5   0   2   9   0   0   0]\n",
    " [  0 489   2   9   3   1  39  22   0   0]\n",
    " [  6   1 484   4   5   0   1   7  10   0]\n",
    " [  2   1  13 361   3  15   7   8  86   0]\n",
    " [  1   0   7   3 418   4   3  43   4   0]\n",
    " [ 17   1   4  17   4 389  15   8   4   0]\n",
    " [ 80   3  49   0   1  24 327   0   0   0]\n",
    " [  0   6   9   5   8   1   7 468   1   0]\n",
    " [  4   1  95  29  14  17   7  10 328   0]\n",
    " [  0   1  33  65 100   0   2 175 117   0]]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.3: Classifying MNIST using simple FFNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classification model\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_shape: int) -> None:\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(nn.BatchNorm1d(input_shape),\n",
    "                                   nn.Linear(in_features=input_shape, out_features=10),\n",
    "                                   nn.Dropout(p=0.5),   # raises from 66% to 70%\n",
    "                                   nn.Sigmoid(),\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_loader = DataLoader(binarized_mnist_train_data, batch_size=100,\n",
    "                                   sampler=classification_sampler(binarized_mnist_train_data.train_labels))\n",
    "\n",
    "testSC = SimpleClassifier(784)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(testSC.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    testSC.train()\n",
    "    for images, labels in classification_loader:\n",
    "        optimizer.zero_grad()\n",
    "        classifications = testSC(images)\n",
    "        loss = criterion(classifications, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluating\n",
    "    if do_test_eval(epoch,epochs,10):\n",
    "        testSC.eval()\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        classifications = testSC(images_test)\n",
    "        preds = torch.max(classifications, 1)[1]\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "        accuracy = confuse_matrix_accuracy(confuse_matrix)\n",
    "        print(\"Epoch %3d, train loss %.3f, test accuracy: %.3f\" % (epoch, loss.item(), accuracy))\n",
    "print()\n",
    "print(confuse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: training results are noise, rerunning training can give from 64% to 69%. Thus at least 3 restarts must be done to determine is a change was beneficial. With only single-layer FFNN I have difficulty getting above 69%. The dropout layer on the output improves results from 65% to 69%. This is surprising for me, because in the output layer each node is necessary, because it is needed to identify one digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4: M2 implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: torch.Size,\n",
    "                 latent_features: int,\n",
    "                 classes: int, \n",
    "                 hidden_layers_preclass: [], \n",
    "                 hidden_layers_postclass: [], \n",
    "                 hidden_layers_classification: [],\n",
    "                 hidden_layers_decoder: []):\n",
    "        super(M2_VAE, self).__init__()\n",
    "        \n",
    "        # Core params\n",
    "        self.input_shape = input_shape\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        self.register_buffer('classification_prior_params', torch.full(torch.Size([1, classes]), 1 / classes))\n",
    "        self.classes = classes\n",
    "        # Having epochs here makes it possible to continue training, with correct epochs counting\n",
    "        self.epochs = 0\n",
    "        \n",
    "        # Cuda enabling\n",
    "        if torch.cuda.is_available():\n",
    "            self.use_cuda = True\n",
    "            self.device = \"cuda:0\"\n",
    "        else:\n",
    "            self.use_cuda = False\n",
    "            self.device = \"cpu\"\n",
    "        \n",
    "        # Classifier construction\n",
    "        classifier_shape = [self.observation_features]\n",
    "        classifier_shape.extend(hidden_layers_classification)\n",
    "        classifier_shape.append(classes)\n",
    "        self.classifier = FF_NetworkConstructor(layers = classifier_shape,\n",
    "                                                pre_batchnorm = False,\n",
    "                                                hidden_batchnorm = True,\n",
    "                                                hidden_activation = nn.ReLU(),\n",
    "                                                final_activation = None)\n",
    "        \n",
    "        # Pre-classification network construction\n",
    "        preclass_shape = [self.observation_features]\n",
    "        preclass_shape.extend(hidden_layers_preclass)\n",
    "        self.preclass_encoder = FF_NetworkConstructor(layers = preclass_shape,\n",
    "                                                      pre_batchnorm = False,\n",
    "                                                      hidden_batchnorm = True,\n",
    "                                                      hidden_activation = nn.ReLU(),\n",
    "                                                      final_activation = nn.ReLU())\n",
    "        \n",
    "        # Post-classification network construction\n",
    "        postclass_shape = [hidden_layers_preclass[-1] + classes]\n",
    "        postclass_shape.extend(hidden_layers_postclass)\n",
    "        postclass_shape.append(latent_features * 2)\n",
    "        self.postclass_encoder = FF_NetworkConstructor(layers = postclass_shape,\n",
    "                                                       pre_batchnorm = False,\n",
    "                                                       hidden_batchnorm = True,\n",
    "                                                       hidden_activation = nn.ReLU(),\n",
    "                                                       final_activation = None)\n",
    "        \n",
    "        # Decoder construction\n",
    "        decoder_shape = [latent_features + classes]\n",
    "        decoder_shape.extend(hidden_layers_decoder)\n",
    "        decoder_shape.append(self.observation_features)\n",
    "        self.decoder = FF_NetworkConstructor(layers = decoder_shape,\n",
    "                                             pre_batchnorm = False,\n",
    "                                             hidden_batchnorm = True,\n",
    "                                             hidden_activation = nn.ReLU(),\n",
    "                                             final_activation = None)\n",
    "        \n",
    "        # Move networks to cuda if available\n",
    "        if self.use_cuda:\n",
    "            self.classifier.cuda()\n",
    "            self.preclass_encoder.cuda()\n",
    "            self.postclass_encoder.cuda()\n",
    "            self.decoder.cuda()\n",
    "    \n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        result = ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        result.mu = result.mu.to(self.device)\n",
    "        result.sigma = result.sigma.to(self.device)\n",
    "        return result\n",
    "    \n",
    "    def classification_prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_classification_prior_params = self.classification_prior_params.expand(batch_size, \n",
    "                                                                                    *self.classification_prior_params.shape[-1:])\n",
    "        result = Categorical(probs = local_classification_prior_params)\n",
    "        return result\n",
    "    \n",
    "    def classification_posterior(self, x: Tensor) -> Distribution:\n",
    "        result = self.classifier(x)\n",
    "        result = result.view(-1, self.classes)\n",
    "        result = Categorical(logits = result)\n",
    "        return result\n",
    "    \n",
    "    def classification_entropy(self, qy: Tensor) -> float:\n",
    "        qy = qy * torch.log(qy)\n",
    "        return -qy.sum(1)\n",
    "        \n",
    "    def encode(self, x: Tensor, y: Tensor = None) -> Tensor:\n",
    "        # Classify if no classification is provided\n",
    "        if y is None:\n",
    "            y = self.classifier(x)\n",
    "        # Encode input\n",
    "        result = self.preclass_encoder(x)\n",
    "        result = torch.cat((result, y), 1)\n",
    "        result = self.postclass_encoder(result)\n",
    "        mu, log_sigma =  result.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def decode(self, z: Tensor, y: Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(torch.cat((z, y), 1))\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits = px_logits)\n",
    "    \n",
    "    def onehot(self, y: int):\n",
    "        result = torch.zeros(y.shape[0], self.classes).to(self.device)\n",
    "        for i in range(len(y)):\n",
    "            result[i][y[i]] = 1\n",
    "        return result\n",
    "    \n",
    "    def loss(self,\n",
    "             px: Distribution, \n",
    "             py: Distribution, \n",
    "             pz: Distribution, \n",
    "             qy: Distribution, \n",
    "             qz: Distribution, \n",
    "             x: Tensor,\n",
    "             y: int, \n",
    "             z: Tensor,\n",
    "             alpha: float,\n",
    "             debug: bool = False) -> float:\n",
    "        x = x.to(self.device)\n",
    "        z = z.to(self.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        py_logprob = py.logits.to(self.device)\n",
    "        \n",
    "        # If labels are not provided, sample from classification posterior\n",
    "        if y is None:\n",
    "            px_logprob = torch.Tensor(0).to(self.device)\n",
    "            qz_logprob = torch.Tensor(0).to(self.device)\n",
    "            pz_logprob = torch.Tensor(0).to(self.device)\n",
    "            for i in range(10):\n",
    "                _y = torch.Tensor(x.shape[0]).fill_(i)\n",
    "                outputs = self.forward(x, _y)\n",
    "                px_logprob = torch.cat((px_logprob, outputs['px'].log_prob(x).sum(dim = 1).view(-1, 1)), 1)\n",
    "                qz_logprob = torch.cat((qz_logprob, outputs['qz'].log_prob(outputs['z']).sum(dim = 1).view(-1, 1)), 1)\n",
    "                pz_logprob = torch.cat((pz_logprob, outputs['pz'].log_prob(outputs['z']).sum(dim = 1).view(-1, 1)), 1)\n",
    "            L = -(px_logprob + py_logprob + pz_logprob - qz_logprob)\n",
    "            U = -(torch.mul(qy.probs, -L).sum(1) + self.classification_entropy(qy.probs))\n",
    "            J = U\n",
    "            return J\n",
    "        else:\n",
    "            y = y.to(self.device)\n",
    "            y = y.view(-1, 1)\n",
    "            px_logprob = px.log_prob(x).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            qz_logprob = qz.log_prob(z).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            pz_logprob = pz.log_prob(z).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            L = -(px_logprob + py_logprob + pz_logprob - qz_logprob)\n",
    "            J = L.gather(1, y)\n",
    "            J_alpha = J - (alpha * qy.logits.gather(1, y))\n",
    "            return J_alpha\n",
    "    \n",
    "    def forward(self, x: Tensor, y: int = None, debug: bool = False) -> Dict[str, Any]:\n",
    "        x = x.to(self.device) # Move to cuda if applicable\n",
    "        x = x.view(x.size(0), -1) # Flatten image input\n",
    "        qy = self.classification_posterior(x) # Classification posterior q(y|x)\n",
    "        py = self.classification_prior(batch_size = x.size(0)) # Classification prior p(y)\n",
    "        pz = self.prior(batch_size=x.size(0)) # Prior p(z)\n",
    "        if y is None: # If labels are not provided, sample from classification posterior\n",
    "            try:\n",
    "                y = qy.sample()\n",
    "            except:\n",
    "                print(self.classifier(x))\n",
    "                raise Exception(\"QY sample error\")\n",
    "        \n",
    "        y = y.to(self.device)\n",
    "        y = y.int()\n",
    "        y = self.onehot(y)\n",
    "        qz = self.encode(x, y) # Approximate posterior q(z|x, y)\n",
    "        z = qz.rsample() # Sample the posterior\n",
    "        px = self.decode(z, y) # Reconstruction p(x|z, y) = B(x | g(z, y))\n",
    "        \n",
    "        return {'px': px, 'py': py, 'pz': pz, 'qy': qy, 'qz': qz, 'z': z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                20, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [100], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 300, 400, 500]) # Network dimensions for decoder\n",
    "print(TestM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE_Trainer:\n",
    "    def __init__(self, network: M2_VAE, train: DataLoader, test: DataLoader, alpha: float, labelled: bool):\n",
    "        self.model = network\n",
    "        self.train_data = train\n",
    "        self.test_data = test\n",
    "        self.alpha = alpha\n",
    "        self.training_data = defaultdict(list)\n",
    "        self.validation_data = defaultdict(list)\n",
    "        self.optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "        self.labelled = labelled\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        for images, labels in self.train_data:\n",
    "            self.optimizer.zero_grad()\n",
    "            if not self.labelled:\n",
    "                labels = None\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha,\n",
    "                                   True).mean()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        self.model.epochs += 1\n",
    "    \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        i = 0\n",
    "        epoch_data = defaultdict(list)\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        for images, labels in self.test_data:\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha,\n",
    "                                   True).mean()\n",
    "            epoch_data['loss'] += [loss.item()]\n",
    "\n",
    "            classifications = self.model.classifier(images.view(-1,28*28).to(self.model.device))\n",
    "            preds = torch.argmax(classifications,1)\n",
    "            confuse_matrix_update(preds, labels, confuse_matrix)\n",
    "\n",
    "        for k, v in epoch_data.items():\n",
    "            self.validation_data[k] += [np.mean(v)]\n",
    "        self.validation_data['class_accu'] += [confuse_matrix_accuracy(confuse_matrix)]\n",
    "\n",
    "        print(\"epoch=%d  test_loss=%.2f  class_accu=%.3f\" % (self.model.epochs, \n",
    "                                                             self.validation_data['loss'][-1], \n",
    "                                                             self.validation_data['class_accu'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#trainer = M2_VAE_Trainer(TestM2, binarized_mnist_train_loader_unlabelled, binarized_mnist_test_loader, 0.1, False)\n",
    "trainer = M2_VAE_Trainer(TestM2, binarized_mnist_train_loader_labelled, binarized_mnist_test_loader, 0.1, True)\n",
    "\n",
    "epochs = 10\n",
    "fn = \"./M2_ok_%dep.pt\" % epochs\n",
    "if False and os.path.isfile(fn):\n",
    "    TestM2.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(TestM2.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_confuse_matrix(TestM2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STYLE TRANSFER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = random.choices(binarized_mnist_train_data,k=10)\n",
    "b = [x[0] for x in a]\n",
    "img = torch.stack(b)\n",
    "fig, axs = plt.subplots(10, 11, figsize=(10, 10), squeeze=False)\n",
    "\n",
    "outputs = TestM2(img)\n",
    "z = outputs['z']\n",
    "\n",
    "for i in range(len(img)):\n",
    "    axs[i, 0].imshow(img[i], cmap='gray')\n",
    "    axs[i, 0].axis('off')\n",
    "    for j in range(10):\n",
    "        image = TestM2.decode(z[i].reshape(1, -1), TestM2.onehot(torch.Tensor([j]).int())).sample().view(28,28).cpu()\n",
    "        axs[i, j + 1].imshow(image, cmap='gray')\n",
    "        axs[i, j + 1].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VAE Eksamen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
