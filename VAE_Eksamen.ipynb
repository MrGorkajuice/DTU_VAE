{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h4TXWhiAGQVJ"
   },
   "source": [
    "**2.1.1: Setup**\n",
    "\n",
    "Importing various required modules and the MNIST dataset. Initializing randomizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEBI-teSY67-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torchvision.datasets import MNIST\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchvision.transforms import ToTensor\n",
    "import statistics\n",
    "import math\n",
    "# Static random seed\n",
    "np.random.seed(89)\n",
    "\n",
    "# Need to convert data to Tensor, because the DataLoader iterator refuses to work with PIL image objects.\n",
    "# Also experienced other trouble when having the PIL image\n",
    "pil2tensor = lambda x: ToTensor()(x).squeeze()   # ToTensor return (64,1,28,28), the squeeze() call removes the 1 dimension\n",
    "\n",
    "# Standard MNIST dataset (not binarized)\n",
    "mnist_train_data = MNIST(\"./temp/\", transform=pil2tensor, download=True, train=True)\n",
    "mnist_test_data = MNIST(\"./temp/\", transform=pil2tensor, download=True, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxXpiIwXGYvY"
   },
   "source": [
    "**2.1.2: Plot 8x8 random samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "ixxaXCQCO_dB",
    "outputId": "95e6471d-aa7d-460d-e80a-e9e0b9080403"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "mnist_train_loader = DataLoader(mnist_train_data, batch_size = 64)\n",
    "images, labels = next(iter(mnist_train_loader))\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(\"%s\" % (labels[i].item()))\n",
    "    ax.axis('off')\n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EAtN1IX7GhDi"
   },
   "source": [
    "**2.1.3: Implement dynamic binarization**\n",
    "\n",
    "Sampling binarized pixels using intensity as probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwTMdXXreBbl"
   },
   "outputs": [],
   "source": [
    "# Setup Bernoulli statistical sampling conversion from grey-scale to binary\n",
    "from torchvision import transforms\n",
    "\n",
    "# When indexing into 'binarized_mnist_xxx_data' we implicitly call '__getitem__', which\n",
    "# normalizes MNIST data. Thus 'transform' gets values in the range [0,1].\n",
    "binarized_mnist_train_data = MNIST(\"./temp/\",\n",
    "                                   download=True,\n",
    "                                   train=True,\n",
    "                                   transform=transforms.Compose([pil2tensor,\n",
    "                                                                 transforms.Lambda(lambda x: torch.bernoulli(x))]))\n",
    "binarized_mnist_test_data = MNIST(\"./temp/\",\n",
    "                                  download=True,\n",
    "                                  train=False,\n",
    "                                  transform=transforms.Compose([pil2tensor,\n",
    "                                                                transforms.Lambda(lambda x: torch.bernoulli(x))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "_Qf9sLMqhyaQ",
    "outputId": "9701d2a4-a4fc-4f79-c854-0ed0fde5995c"
   },
   "outputs": [],
   "source": [
    "# Plot same image a couple of times to verify we are doing statistical sampling every time the image is drawn\n",
    "fig, axs = plt.subplots(1, 4, figsize=(12, 3), squeeze=False)\n",
    "for ax in axs.flat:\n",
    "    sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "    assert torch.max(sample) == 1.0\n",
    "    assert torch.min(sample) == 0.0\n",
    "    ax.imshow(sample, cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oLIEWEXOoOpt"
   },
   "source": [
    "**2.1.4: Plot binarized MNIST samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "-9Jj6BslTiPt",
    "outputId": "2c88f850-a28e-4b62-8280-10c5e8daa311"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "binarized_mnist_train_loader = DataLoader(binarized_mnist_train_data, batch_size = 64)\n",
    "images, labels = next(iter(binarized_mnist_train_loader))\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(images[i], cmap='gray')\n",
    "    ax.set_title(\"%s\" % (labels[i].item()))\n",
    "    ax.axis('off')\n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAfNjJ4vrJMq"
   },
   "source": [
    "**2.2.1.1: VAE implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "370tki2E3CBG"
   },
   "outputs": [],
   "source": [
    "# Implement reparameterized diagonal gaussian\n",
    "from torch.distributions import Distribution\n",
    "\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    def __init__(self, mu: Tensor, log_sigma: Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        return self.mu + self.sigma*self.sample_epsilon()\n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        from torch.distributions import Normal \n",
    "        return  Normal(loc=self.mu, scale=self.sigma).log_prob(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF5c_hYM8v-o"
   },
   "outputs": [],
   "source": [
    "# Return sum of values in all dimenensions, except the first one, which is assumed to be batch\n",
    "def reduce(x: Tensor) -> Tensor:\n",
    "    return x.view(x.size(0), -1).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHWnmyLfrTBF"
   },
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "# Define hidden layer topology - list of sizes of hidden layers\n",
    "encoder_dimensions = [512, 256, 128]\n",
    "decoder_dimensions = [128, 256, 512]\n",
    "apply_per_layer_batchnorm = False\n",
    "\n",
    "# Implement VAE\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_shape:torch.Size, latent_features:int) -> None:\n",
    "        super(VariationalAutoEncoder, self).__init__()\n",
    "\n",
    "        # Core parameters\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        #self.prior_params = torch.zeros(torch.Size([1, 2*latent_features]))\n",
    "        \n",
    "        # Dynamically constructing the encoder network\n",
    "        encoder_constructor = []\n",
    "        encoder_constructor.append(nn.Linear(in_features=self.observation_features, out_features=encoder_dimensions[0]))\n",
    "        encoder_constructor.append(nn.ReLU())\n",
    "        if apply_per_layer_batchnorm:\n",
    "            encoder_constructor.append(nn.BatchNorm1d(num_features=encoder_dimensions[0]))\n",
    "        for i in range(len(encoder_dimensions)-1):\n",
    "            encoder_constructor.append(nn.Linear(in_features=encoder_dimensions[i], out_features=encoder_dimensions[i+1]))\n",
    "            encoder_constructor.append(nn.ReLU())\n",
    "            if apply_per_layer_batchnorm:\n",
    "                encoder_constructor.append(nn.BatchNorm1d(num_features=encoder_dimensions[i+1]))\n",
    "        encoder_constructor.append(nn.Linear(in_features=encoder_dimensions[-1], out_features=2*self.latent_features))\n",
    "        self.encoder = nn.Sequential(*encoder_constructor)\n",
    "\n",
    "        # Dynamically constructing the decoder network\n",
    "        decoder_constructor = []\n",
    "        decoder_constructor.append(nn.Linear(in_features=self.latent_features, out_features=decoder_dimensions[0]))\n",
    "        decoder_constructor.append(nn.ReLU())\n",
    "        if apply_per_layer_batchnorm:\n",
    "            decoder_constructor.append(nn.BatchNorm1d(num_features=decoder_dimensions[0]))\n",
    "        for i in range(len(decoder_dimensions)-1):\n",
    "            decoder_constructor.append(nn.Linear(in_features=decoder_dimensions[i], out_features=decoder_dimensions[i+1]))\n",
    "            decoder_constructor.append(nn.ReLU())\n",
    "            if apply_per_layer_batchnorm:\n",
    "                decoder_constructor.append(nn.BatchNorm1d(num_features=decoder_dimensions[i+1]))\n",
    "        decoder_constructor.append(nn.Linear(in_features=decoder_dimensions[-1], out_features=self.observation_features))\n",
    "        self.decoder = nn.Sequential(*decoder_constructor)\n",
    "    \n",
    "    # Encode input into posterior distribution\n",
    "    def encode(self, x: Tensor) -> Distribution:\n",
    "        h_x = self.encoder(x)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    # Decode latent variables into reconstruction\n",
    "    def decode(self, z: Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(z)\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits=px_logits)\n",
    "    \n",
    "    # Get the prior distribution\n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    # Sample from a provided distribution\n",
    "    def sample(self, distribution: ReparameterizedDiagonalGaussian) -> Tensor:\n",
    "        return distribution.rsample()\n",
    "    \n",
    "    # Compute the ELBO\n",
    "    def elbo(self, prior: Distribution, posterior: Distribution, reconstruction: Distribution, x: Tensor, z: Tensor) -> float:\n",
    "        tst = reconstruction.sample()\n",
    "        x = x.view(x.size(0), -1)\n",
    "        log_px = reduce(reconstruction.log_prob(x))\n",
    "        log_pz = reduce(prior.log_prob(z))\n",
    "        log_qz = reduce(posterior.log_prob(z))\n",
    "        kl = log_qz - log_pz\n",
    "        elbo = log_px - kl\n",
    "        return elbo\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Dict[str, Any]:\n",
    "        # flatten the input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.encode(x)\n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        z = qz.rsample()\n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.decode(z)\n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pxhZisS33nwM",
    "outputId": "e40f6ce3-9970-43db-9b5f-8cea8c7e372e"
   },
   "outputs": [],
   "source": [
    "# Instantiate a VAE\n",
    "testVAE = VariationalAutoEncoder(sample.flatten().shape, 5)\n",
    "print(testVAE.encoder)\n",
    "print(testVAE.decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Xht6E_a-Mee"
   },
   "source": [
    "**2.2.1.2: Print samples from untrained VAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Decoding sample from prior\n",
    "testVAE.cpu()\n",
    "testVAE.eval()\n",
    "\n",
    "prior = testVAE.prior(64)\n",
    "prior_sample = testVAE.sample(prior)\n",
    "decoded_prior_sample = testVAE.decode(prior_sample)\n",
    "sampled_decode_content = decoded_prior_sample.sample().view(64, 28, 28)\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 729
    },
    "id": "cwWZmv9Y9Urq",
    "outputId": "a4b073a4-af3f-4872-fc57-3eb7afa0f798"
   },
   "outputs": [],
   "source": [
    "# Method 2: Reconstruction of input from binarized MNIST\n",
    "a = random.choices(binarized_mnist_train_data,k=64)\n",
    "b = [x[0] for x in a]\n",
    "img = torch.stack(b)\n",
    "sampled_decode_content = testVAE(img)['px'].sample().view(-1,28,28)\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgglyZU6FNZl"
   },
   "source": [
    "**2.2.1.3: Compute ELBO of 64 samples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Pe-W5XaETD7",
    "outputId": "ba5de8d1-fe2d-4594-ca24-983f4859bd23"
   },
   "outputs": [],
   "source": [
    "sample_cnt = 64\n",
    "samples = np.zeros(shape=(sample_cnt, 784))\n",
    "labels = np.zeros(shape=(sample_cnt, 1))\n",
    "for i in range(sample_cnt):\n",
    "    sample = random.choice(binarized_mnist_train_data)\n",
    "    samples[i] = sample[0].view(1, -1).numpy()\n",
    "    labels[i] = sample[1]\n",
    "\n",
    "prior = testVAE.prior(sample_cnt)\n",
    "samples_tensor = Tensor(samples)\n",
    "posterior = testVAE.encode(samples_tensor)\n",
    "z = testVAE.sample(posterior) # Random sampling\n",
    "reconstruction = testVAE.decode(z)\n",
    "elbo = testVAE.elbo(prior, posterior, reconstruction, samples_tensor, z) \n",
    "\n",
    "# 'float64' required because 'stdev' chokes on 'float32' which is the default type when detaching from GPU\n",
    "elbo_ary = elbo.detach().numpy().astype('float64')\n",
    "elbo_stddev = statistics.stdev(elbo_ary)\n",
    "elbo_mean = statistics.mean(elbo_ary)\n",
    "print(\"ELBO on %d train data: %.1f +/-%.1f\" % (sample_cnt, elbo_mean,elbo_stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2.1 and 2.2.2.2: Implementing train and test methods in training helper class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "class VAE_Trainer:\n",
    "    def __init__(self, network: VariationalAutoEncoder, train: DataLoader, test: DataLoader):\n",
    "        self.VAE = network\n",
    "        self.train_data = train\n",
    "        self.test_data = test\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda:0\"\n",
    "            network.cuda()\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "            network.cpu()\n",
    "        self.optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)\n",
    "    \n",
    "    def train(self):\n",
    "        self.VAE.train()\n",
    "        for images, labels in self.train_data:\n",
    "            images = images.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.VAE(images)\n",
    "            loss = -self.VAE.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "    \n",
    "    def test(self):\n",
    "        self.VAE.eval()\n",
    "        losses = []\n",
    "        i = 0\n",
    "        for images, labels in self.test_data:\n",
    "            images = images.to(self.device)\n",
    "            outputs = self.VAE(images)\n",
    "            elbos = self.VAE.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).cpu().detach().numpy()\n",
    "            losses = np.append(losses, elbos)\n",
    "        loss = -np.mean(losses)\n",
    "        print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2.3: Training the network**\n",
    "\n",
    "**ToDo:** Implement state saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_mnist_test_loader = DataLoader(binarized_mnist_test_data, batch_size = 64)\n",
    "\n",
    "trainer = VAE_Trainer(testVAE, binarized_mnist_train_loader, binarized_mnist_test_loader)\n",
    "epochs = 200\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"Training epoch \", i)\n",
    "    trainer.train()\n",
    "    print(\"Testing epoch \", i)\n",
    "    trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2.2.4: Generating samples from trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testVAE.cpu()\n",
    "testVAE.eval()\n",
    "\n",
    "prior = testVAE.prior(64)\n",
    "prior_sample = testVAE.sample(prior)\n",
    "decoded_prior_sample = testVAE.decode(prior_sample)\n",
    "sampled_decode_content = decoded_prior_sample.sample().view(64, 28, 28)\n",
    "\n",
    "fig, axs = plt.subplots(8, 8, figsize=(10, 10), squeeze=False)\n",
    "i = 0\n",
    "for ax in axs.flat:\n",
    "    ax.imshow(sampled_decode_content[i], cmap='gray')\n",
    "    ax.axis('off') \n",
    "    i += 1\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Pe-W5XaETD7",
    "outputId": "ba5de8d1-fe2d-4594-ca24-983f4859bd23"
   },
   "outputs": [],
   "source": [
    "sample_cnt = binarized_mnist_test_data.data.shape[0]\n",
    "#sample_cnt = 100\n",
    "samples_tensor = torch.empty(sample_cnt,28,28)\n",
    "for idx in range(samples_tensor.shape[0]):\n",
    "    samples_tensor[idx] = binarized_mnist_test_data[idx][0]\n",
    "\n",
    "prior = testVAE.prior(sample_cnt)\n",
    "samples_tensor = samples_tensor.view(sample_cnt,-1)\n",
    "samples_tensor.shape\n",
    "posterior = testVAE.encode(samples_tensor)\n",
    "z = testVAE.sample(posterior)\n",
    "reconstruction = testVAE.decode(z)\n",
    "elbo = testVAE.elbo(prior, posterior, reconstruction, samples_tensor, z) \n",
    "\n",
    "# 'float64' required because 'stdev' chokes on 'float32' which is the default type when detaching from GPU\n",
    "elbo_ary = elbo.detach().numpy().astype('float64')\n",
    "elbo_stddev = statistics.stdev(elbo_ary)\n",
    "elbo_mean = statistics.mean(elbo_ary)\n",
    "print(\"ELBO on %d test data: %.1f +/-%.1f\" % (sample_cnt, elbo_mean,elbo_stddev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1: Extracting 10 samples per class for classification training**\n",
    "\n",
    "**ToDo:** Consider more elegant solution for classification_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import functools\n",
    "\n",
    "def classification_sampler(labels):\n",
    "    indices = []\n",
    "    for i in range(10):\n",
    "        #(tmp_indices,) = np.where(functools.reduce(lambda x, y: x | y, [labels.numpy() == i]))\n",
    "        tmp_indices = np.where(labels.numpy() == i)[0]\n",
    "        indices.append(random.choices(tmp_indices, k=10))\n",
    "    indices = torch.Tensor(indices)\n",
    "    indices = indices.view(1, -1).squeeze().int()\n",
    "    return SubsetRandomSampler(indices)\n",
    "    \n",
    "classification_loader = DataLoader(binarized_mnist_train_data, batch_size=25,\n",
    "                                   sampler=classification_sampler(binarized_mnist_train_data.train_labels))\n",
    "# Accuracy of Test Accuracy estimates based on batch_size\n",
    "#  10k: baseline\n",
    "# 2000: 0.5% 0.9% 1.6%\n",
    "# 5000: 0.2% 0.9% 1.2%\n",
    "# Adding 2.5 sec by using all test data instead of just 1000. Worth the price.\n",
    "classification_loader_test = DataLoader(binarized_mnist_test_data, shuffle=True, batch_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual check that the same 100 pictures are printed, and only permutated. Evaluate this cell a couple of times.\n",
    "for images, labels in classification_loader:\n",
    "    fig, axs = plt.subplots(1, 25, figsize=(20, 25), squeeze=False)\n",
    "    for i,ax in enumerate(axs.flat):\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "        ax.axis('off') \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.2: Training classifier on latent representation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classification model\n",
    "\n",
    "class LatentClassifier(nn.Module):\n",
    "    def __init__(self, latent_features:int) -> None:\n",
    "        super(LatentClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(nn.BatchNorm1d(latent_features*2),    # MAGIC! raises accurcay from 50% to 75%\n",
    "                                   nn.Linear(in_features=latent_features*2, out_features=10), \n",
    "                                   nn.Sigmoid(),  # Initial network used ReLU in output layer, however this was prone to give\n",
    "                                                  # dead outputs, eg. classifier would often train so some classes would \n",
    "                                                  # never be guessed\n",
    "                                   nn.Dropout(p=0.5)        # raises accuracy from 75% to 83%\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class builds a M1 classifier. Output is logits tensor. UNDER CONSTRUCTION.\n",
    "class M1Classifier(nn.Module):\n",
    "    def __init__(self, VAE: nn.Module, LatentClassifier: nn.Module) -> None:\n",
    "        super(M1Classifier, self).__init__()\n",
    "        self.VAE = VAE\n",
    "        self.LatentClassifier = LatentClassifier\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test_eval(cnt, epochs, num_of_evals):\n",
    "    # Used for doing occasional print of test evaluation data.\n",
    "    # Return true 'num_of_evals' times when running range(epochs) training\n",
    "    # Will also trigger at start and end\n",
    "    modulu = math.ceil(epochs/(num_of_evals-1))\n",
    "    return cnt==0 or cnt==epochs-1 or cnt % modulu == modulu-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse_matrix_update(predictions, labels, confusion_matrix):\n",
    "    # Update 'confusion_matrix' according the the prodictions/labels vectors.\n",
    "    # Confusion_matrix rows are actual labels, and columns predictions. E.g. row 0 \n",
    "    # tells how the classifier predicted '0', (0,0) represents correct predictions, \n",
    "    # (0,1) is how many times a '0' was classified as a '1'\n",
    "    for pre, lbl in zip(predictions, labels):\n",
    "        confusion_matrix[lbl,pre] += 1\n",
    "def confuse_matrix_accuracy(cm):\n",
    "    return cm.trace()/cm.sum()\n",
    "if False:\n",
    "    cm = np.zeros((10,10))\n",
    "    pred=torch.tensor([2,9,8,6])\n",
    "    lab =torch.tensor([2,9,8,4])\n",
    "    confuse_matrix_update(pred,lab,cm)\n",
    "    confuse_matrix_update(pred,lab,cm)\n",
    "    print(cm, confuse_matrix_accuracy(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "testVAE.eval()\n",
    "\n",
    "testLC = LatentClassifier(5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(testLC.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.Adam(testLC.parameters(), lr=0.005)\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "images_test, labels_test = next(iter(classification_loader_test))\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    testLC.train()\n",
    "    for images, labels in classification_loader:\n",
    "        outputs = testVAE(images)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        optimizer.zero_grad()\n",
    "        classifications = testLC(classifier_input)\n",
    "        loss = criterion(classifications, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluating\n",
    "    if do_test_eval(epoch,epochs,10):\n",
    "        testLC.eval()\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        outputs = testVAE(images_test)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        classifications = testLC(classifier_input)\n",
    "        preds = torch.max(classifications, 1)[1]\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "        accuracy = confuse_matrix_accuracy(confuse_matrix)\n",
    "        print(\"Epoch %3d, train loss %.3f, test accuracy: %.3f\" % (epoch, loss.item(), accuracy))\n",
    "print()\n",
    "print(confuse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_loader = DataLoader(binarized_mnist_train_data, batch_size=100,\n",
    "                                   sampler=classification_sampler(binarized_mnist_train_data.train_labels))\n",
    "optimizer = optim.Adam(testLC.parameters(), lr=0.0005)\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    testLC.train()\n",
    "    for images, labels in classification_loader:\n",
    "        outputs = testVAE(images)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        optimizer.zero_grad()\n",
    "        classifications = testLC(classifier_input)\n",
    "        loss = criterion(classifications, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluating\n",
    "    if do_test_eval(epoch,epochs,10):\n",
    "        testLC.eval()\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        outputs = testVAE(images_test)\n",
    "        classifier_input = torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1)\n",
    "        classifications = testLC(classifier_input)\n",
    "        preds = torch.max(classifications, 1)[1]\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "        accuracy = confuse_matrix_accuracy(confuse_matrix)\n",
    "        print(\"Epoch %3d, train loss %.3f, test accuracy: %.3f\" % (epoch, loss.item(), accuracy))\n",
    "print()\n",
    "print(confuse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cells notes:\n",
    "Initial results showed large accuracy variation, varying from 0.40 to 0.73 accuracy. Confusion matrix revealed that some numbers were never chosen. E.g. below where classifier never outputs a '9' classification.\n",
    "<code>\n",
    "[[464   0  12   5   0   2   9   0   0   0]\n",
    " [  0 489   2   9   3   1  39  22   0   0]\n",
    " [  6   1 484   4   5   0   1   7  10   0]\n",
    " [  2   1  13 361   3  15   7   8  86   0]\n",
    " [  1   0   7   3 418   4   3  43   4   0]\n",
    " [ 17   1   4  17   4 389  15   8   4   0]\n",
    " [ 80   3  49   0   1  24 327   0   0   0]\n",
    " [  0   6   9   5   8   1   7 468   1   0]\n",
    " [  4   1  95  29  14  17   7  10 328   0]\n",
    " [  0   1  33  65 100   0   2 175 117   0]]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.3: Classifying MNIST using simple FFNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classification model\n",
    "\n",
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_shape: int) -> None:\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(nn.BatchNorm1d(input_shape),\n",
    "                                   nn.Linear(in_features=input_shape, out_features=10),\n",
    "                                   nn.Dropout(p=0.5),   # raises from 66% to 70%\n",
    "                                   nn.Sigmoid(),\n",
    "                                  )\n",
    "        \n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_loader = DataLoader(binarized_mnist_train_data, batch_size=100,\n",
    "                                   sampler=classification_sampler(binarized_mnist_train_data.train_labels))\n",
    "\n",
    "testSC = SimpleClassifier(784)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(testSC.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    testSC.train()\n",
    "    for images, labels in classification_loader:\n",
    "        optimizer.zero_grad()\n",
    "        classifications = testSC(images)\n",
    "        loss = criterion(classifications, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluating\n",
    "    if do_test_eval(epoch,epochs,10):\n",
    "        testSC.eval()\n",
    "        confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "        classifications = testSC(images_test)\n",
    "        preds = torch.max(classifications, 1)[1]\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "        accuracy = confuse_matrix_accuracy(confuse_matrix)\n",
    "        print(\"Epoch %3d, train loss %.3f, test accuracy: %.3f\" % (epoch, loss.item(), accuracy))\n",
    "print()\n",
    "print(confuse_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: training results are noise, rerunning training can give from 64% to 69%. Thus at least 3 restarts must be done to determine is a change was beneficial. With only single-layer FFNN I have difficulty getting above 69%. The dropout layer on the output improves results from 65% to 69%. This is surprising for me, because in the output layer each node is necessary, because it is needed to identify one digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.4: M2 implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: torch.Size,\n",
    "                 latent_features: int,\n",
    "                 classes: int, \n",
    "                 hidden_layers_preclass: [], \n",
    "                 hidden_layers_postclass: [], \n",
    "                 hidden_layers_classification: [],\n",
    "                 hidden_layers_decoder: []):\n",
    "        super(M2_VAE, self).__init__()\n",
    "        \n",
    "        # Core params\n",
    "        self.input_shape = input_shape\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        \n",
    "        # Classifier construction\n",
    "        classifier_constructor = []\n",
    "        classifier_constructor.append(nn.Linear(in_features = self.observation_features,\n",
    "                                                out_features = hidden_layers_classification[0]))\n",
    "        classifier_constructor.append(nn.ReLU())\n",
    "        for i in range(len(hidden_layers_classification) - 1):\n",
    "            classifier_constructor.append(nn.Linear(in_features = hidden_layers_classification[i],\n",
    "                                                    out_features = hidden_layers_classification[i + 1]))\n",
    "            classifier_constructor.append(nn.ReLU())\n",
    "        classifier_constructor.append(nn.Linear(in_features = hidden_layers_classification[-1],\n",
    "                                                out_features = classes))\n",
    "        classifier_constructor.append(nn.Softmax(0))\n",
    "        self.classifier = nn.Sequential(*classifier_constructor)\n",
    "        \n",
    "        # Pre-classification network constructor\n",
    "        preclass_constructor = []\n",
    "        preclass_constructor.append(nn.Linear(in_features = self.observation_features,\n",
    "                                              out_features = hidden_layers_preclass[0]))\n",
    "        preclass_constructor.append(nn.ReLU())\n",
    "        for i in range(len(hidden_layers_preclass) - 1):\n",
    "            preclass_constructor.append(nn.Linear(in_features = hidden_layers_preclass[i],\n",
    "                                                  out_features = hidden_layers_preclass[i + 1]))\n",
    "            preclass_constructor.append(nn.ReLU())\n",
    "        self.preclass_encoder = nn.Sequential(*preclass_constructor)\n",
    "        \n",
    "        # Post-classification network constructor\n",
    "        postclass_constructor = []\n",
    "        postclass_constructor.append(nn.Linear(in_features = hidden_layers_preclass[-1] + classes, \n",
    "                                               out_features = hidden_layers_postclass[0]))\n",
    "        postclass_constructor.append(nn.ReLU())\n",
    "        for i in range(len(hidden_layers_postclass) - 1):\n",
    "            postclass_constructor.append(nn.Linear(in_features = hidden_layers_postclass[i],\n",
    "                                                   out_features = hidden_layers_postclass[i + 1]))\n",
    "            postclass_constructor.append(nn.ReLU())\n",
    "        postclass_constructor.append(nn.Linear(in_features = hidden_layers_postclass[-1], \n",
    "                                               out_features = latent_features * 2))\n",
    "        postclass_constructor.append(nn.ReLU())\n",
    "        self.postclass_encoder = nn.Sequential(*postclass_constructor)\n",
    "        \n",
    "        # Decoder constructor\n",
    "        decoder_constructor = []\n",
    "        decoder_constructor.append(nn.Linear(in_features = latent_features + classes,\n",
    "                                             out_features = hidden_layers_decoder[0]))\n",
    "        decoder_constructor.append(nn.ReLU())\n",
    "        for i in range(len(hidden_layers_decoder) - 1):\n",
    "            decoder_constructor.append(nn.Linear(in_features = hidden_layers_decoder[i],\n",
    "                                                 out_features = hidden_layers_decoder[i + 1]))\n",
    "            decoder_constructor.append(nn.ReLU())\n",
    "        decoder_constructor.append(nn.Linear(in_features = hidden_layers_decoder[-1],\n",
    "                                             out_features = self.observation_features))\n",
    "        self.decoder = nn.Sequential(*decoder_constructor)\n",
    "        \n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def encode(self, x: Tensor, y: Tensor = None) -> Tensor:\n",
    "        # Classify if no classification is provided\n",
    "        if y is None:\n",
    "            y = self.classifier(x)\n",
    "        # Encode input\n",
    "        result = self.preclass_encoder(x)\n",
    "        result = torch.cat((result, y), 0)\n",
    "        result = self.postclass_encoder(result)\n",
    "    \n",
    "    def decode(self, z:Tensor, y:Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(torch.cat((z, y), 0))\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits=px_logits)\n",
    "    \n",
    "    def forward(self, x: Tensor, y: Tensor = None) -> Dict[str, Any]:\n",
    "        # Flatten image input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # Approximate posterior q(z|x, y)\n",
    "        qz = encode(x, y)\n",
    "        # Prior p(z)\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        # Sample the posterior\n",
    "        z = qz.rsample()\n",
    "        # Reconstruction p(x|z, y) = B(x | g(z, y))\n",
    "        px = self.decode(z, y)\n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z, 'y': y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "TestM2 = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                10, # Latent features\n",
    "                10, # Classes\n",
    "                [34], # Network dimensions for encoder before adding classifications\n",
    "                [67], # Network dimensions for encoder after adding classification\n",
    "                [200, 100], # Network dimensions for classification network\n",
    "                [200, 300, 400, 500]) # Network dimensions for decoder\n",
    "print(TestM2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VAE Eksamen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
