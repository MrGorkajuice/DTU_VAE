{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semi-Supervised Deep Learning project\n",
    "This notebook contains the Python code for the final project by the group \"Uffe & Axel\" in the 02456 Deep Learning course autumn 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook is a series of cells that define parameters for a network, executes training, and saves the generated model. When these models are present along with this notebook, default behavior is to load and evaluate the associated model, rather than training a new model. To override this behavior, set the attribute in the following cell to False.\n",
    "\n",
    "**WARNING:** For retraining all models, expect execution time in the ~24 hour range even on high-end GPU's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_saved_models = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SEBI-teSY67-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "from torchvision.datasets import MNIST\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import Bernoulli\n",
    "from typing import Dict, Any\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, RandomSampler\n",
    "from collections import defaultdict\n",
    "from IPython.display import Image, display, clear_output\n",
    "import statistics\n",
    "import math\n",
    "import os.path\n",
    "import socket\n",
    "from torch.distributions import Categorical\n",
    "# Static random seed\n",
    "np.random.seed(89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LAMBDAS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to convert data to Tensor, because the DataLoader iterator refuses to work with PIL image objects.\n",
    "pil2tensor = lambda x: ToTensor()(x).squeeze()   # ToTensor return (64,1,28,28), the squeeze() call removes the 1 dimension\n",
    "\n",
    "# Binarize method for binarized dataset\n",
    "binarize = lambda x: torch.bernoulli(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATASETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XwTMdXXreBbl"
   },
   "outputs": [],
   "source": [
    "mnist_train_data = MNIST(\"./temp/\", transform=pil2tensor, download=True, train=True)\n",
    "mnist_test_data = MNIST(\"./temp/\", transform=pil2tensor, download=True, train=False)\n",
    "\n",
    "binarized_mnist_train_data = MNIST(\"./temp/\",\n",
    "                                   download=True,\n",
    "                                   train=True,\n",
    "                                   transform=transforms.Compose([pil2tensor,\n",
    "                                                                 binarize]))\n",
    "binarized_mnist_test_data = MNIST(\"./temp/\",\n",
    "                                  download=True,\n",
    "                                  train=False,\n",
    "                                  transform=transforms.Compose([pil2tensor,\n",
    "                                                                binarize]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATALOADERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_indices(dataset, total_labels):\n",
    "    # return random list of indicies into 'dataset' that point to an equal amount of each label 0 to 9\n",
    "    idx_list = []\n",
    "    for target in range(10):\n",
    "        idx_list += random.sample(list(np.where([dataset.targets.numpy() == target])[1]), k=int(total_labels/10))\n",
    "    return idx_list\n",
    "for cnt, idx in enumerate(label_indices(binarized_mnist_train_data, 10)):\n",
    "    assert cnt == binarized_mnist_train_data[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_setup(labelled_size = 10000,\n",
    "                 unlabelled_size = None,    # None: 50k - lbl_size\n",
    "                 validation_size = 10000,\n",
    "                 test_size = None,          # None: use all 10k\n",
    "                 batch_size = 64):\n",
    "    '''Setup all data loaders, providing labelled, unlabelled, validation & test samples'''\n",
    "    global binarized_mnist_train_loader_labelled\n",
    "    global binarized_mnist_train_loader_unlabelled\n",
    "    global binarized_mnist_train_loader_validation\n",
    "    global binarized_mnist_test_loader\n",
    "    if unlabelled_size == None:\n",
    "        unlabelled_size = 50000 - labelled_size\n",
    "    indices_train = np.arange(len(binarized_mnist_train_data)) # 60000\n",
    "\n",
    "    labelled_idx = label_indices(binarized_mnist_train_data, labelled_size)\n",
    "    unlabelled_idx = random.sample(list(np.setdiff1d(indices_train, labelled_idx)\n",
    "                                       ), k=unlabelled_size)\n",
    "    validation_idx = random.sample(list(np.setdiff1d(indices_train, \n",
    "                                                     np.concatenate((labelled_idx,unlabelled_idx)))\n",
    "                                       ), k=validation_size)\n",
    "\n",
    "    # Last, generate the dataloaders\n",
    "    binarized_mnist_train_loader_labelled = DataLoader(binarized_mnist_train_data, \n",
    "                                                       batch_size = batch_size,\n",
    "                                                       sampler = SubsetRandomSampler(labelled_idx))\n",
    "    if unlabelled_size == 0:\n",
    "        # The M2 trainer skips unlabelled training if train_loader is 'None'\n",
    "        binarized_mnist_train_loader_unlabelled = None\n",
    "    else:\n",
    "        binarized_mnist_train_loader_unlabelled = DataLoader(binarized_mnist_train_data, \n",
    "                                                             batch_size = batch_size, \n",
    "                                                             sampler = SubsetRandomSampler(unlabelled_idx))\n",
    "    binarized_mnist_train_loader_validation = DataLoader(binarized_mnist_train_data, \n",
    "                                                         batch_size = batch_size, \n",
    "                                                         sampler = SubsetRandomSampler(validation_idx))\n",
    "    if test_size == None:\n",
    "        test_size = len(binarized_mnist_test_data)  # 10000\n",
    "    indices_test = np.arange(test_size)\n",
    "    binarized_mnist_test_loader = DataLoader(binarized_mnist_test_data, \n",
    "                                             batch_size = 64, \n",
    "                                             sampler = SubsetRandomSampler(indices_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_setup(labelled_size=10000, \n",
    "             unlabelled_size=40000, \n",
    "             validation_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-binarized dataloader\n",
    "indices_train = list(range(len(mnist_train_data))) # 60000\n",
    "mnist_train_loader = DataLoader(mnist_train_data, \n",
    "                                batch_size = 64, \n",
    "                                sampler = SubsetRandomSampler(indices_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REPARAMETERIZED DIAGONAL GUASSIAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "370tki2E3CBG"
   },
   "outputs": [],
   "source": [
    "# Implement reparameterized diagonal gaussian\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    def __init__(self, mu: Tensor, log_sigma: Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        return self.mu + self.sigma*self.sample_epsilon()\n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        from torch.distributions import Normal \n",
    "        return  Normal(loc=self.mu, scale=self.sigma).log_prob(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NETWORK CONSTRUCTOR HELPER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for easier creation of FFNN's in accordance with provided specifications\n",
    "def FF_NetworkConstructor(layers: [],\n",
    "                          pre_batchnorm: bool,\n",
    "                          hidden_batchnorm: bool,\n",
    "                          hidden_activation: nn.ReLU(),\n",
    "                          dropout_prob: float,\n",
    "                          final_activation: None) -> nn.Sequential:\n",
    "    constructor = []\n",
    "    if pre_batchnorm:\n",
    "        constructor.append(nn.BatchNorm1d(num_features = layers[0]))\n",
    "    for i in range(len(layers) - 2):\n",
    "        constructor.append(nn.Linear(in_features = layers[i],\n",
    "                                     out_features = layers[i + 1]))\n",
    "        constructor.append(hidden_activation)\n",
    "        if hidden_batchnorm:\n",
    "            constructor.append(nn.BatchNorm1d(num_features = layers[i + 1]))\n",
    "        constructor.append(nn.Dropout(p=dropout_prob))\n",
    "    \n",
    "    constructor.append(nn.Linear(in_features = layers[-2], out_features = layers[-1]))\n",
    "    if final_activation is not None:\n",
    "        constructor.append(final_activation)\n",
    "    result = nn.Sequential(*constructor)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA ANALYSIS SUPPORT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confuse_matrix_update(predictions, labels, confusion_matrix):\n",
    "    # Update 'confusion_matrix' according the the prodictions/labels vectors.\n",
    "    # Confusion_matrix rows are actual labels, and columns predictions. E.g. row 0 \n",
    "    # tells how the classifier predicted '0', (0,0) represents correct predictions, \n",
    "    # (0,1) is how many times a '0' was classified as a '1'\n",
    "    for pre, lbl in zip(predictions, labels):\n",
    "        confusion_matrix[lbl,pre] += 1\n",
    "def confuse_matrix_accuracy(cm):\n",
    "    return 0.0 if cm.sum() == 0 else cm.trace()/cm.sum()\n",
    "if False:\n",
    "    cm = np.zeros((10,10))\n",
    "    pred=torch.tensor([2,9,8,6])\n",
    "    lab =torch.tensor([2,9,8,4])\n",
    "    confuse_matrix_update(pred,lab,cm)\n",
    "    confuse_matrix_update(pred,lab,cm)\n",
    "    print(cm, confuse_matrix_accuracy(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confuse_matrix(VAE, test_loader = None):\n",
    "    # print confuse_matrix for 'VAE' which is assumed to have function 'classifier'\n",
    "    # and variable 'device' indicating cpu or cuda.\n",
    "    if test_loader == None:\n",
    "        test_loader = binarized_mnist_test_loader\n",
    "    confuse_matrix = np.zeros((10,10)).astype('int')\n",
    "    for images_test,labels_test in test_loader:\n",
    "        images_test = images_test.to(VAE.device)\n",
    "        classifications = VAE.classifier(images_test.view(-1,28*28))\n",
    "        preds = torch.argmax(classifications,1)\n",
    "        confuse_matrix_update(preds, labels_test, confuse_matrix)\n",
    "    print(confuse_matrix)\n",
    "    print(\"Classifier accuracy: %.3f\" % confuse_matrix_accuracy(confuse_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper class to handle plotting of training progress\n",
    "class Plotter:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.train_accuracies = []\n",
    "        self.valid_losses = []\n",
    "        self.valid_accuracies = []\n",
    "        self.test_losses = []\n",
    "        self.test_accuracies = []\n",
    "        \n",
    "        self.train_loss_buffer = []\n",
    "        self.train_labels_buffer = []\n",
    "        self.train_preds_buffer = []\n",
    "        self.valid_loss_buffer = []\n",
    "        self.valid_labels_buffer = []\n",
    "        self.valid_preds_buffer = []\n",
    "        self.test_loss_buffer = []\n",
    "        self.test_labels_buffer = []\n",
    "        self.test_preds_buffer = []\n",
    "    \n",
    "    def append_train(self, loss: Tensor = None, preds: Tensor = None, targets: Tensor = None):\n",
    "        if loss is not None:\n",
    "            self.train_loss_buffer = np.append(self.train_loss_buffer, loss.cpu().detach().numpy())\n",
    "        if preds is not None and targets is not None:\n",
    "            self.train_labels_buffer = np.append(self.train_labels_buffer, targets)\n",
    "            self.train_preds_buffer = np.append(self.train_preds_buffer, preds.cpu().detach().numpy())\n",
    "    \n",
    "    def append_valid(self, loss: Tensor = None, preds: Tensor = None, targets: Tensor = None):\n",
    "        if loss is not None:\n",
    "            self.valid_loss_buffer = np.append(self.valid_loss_buffer, loss.cpu().detach().numpy())\n",
    "        if preds is not None and targets is not None:\n",
    "            self.valid_labels_buffer = np.append(self.valid_labels_buffer, targets)\n",
    "            self.valid_preds_buffer = np.append(self.valid_preds_buffer, preds.cpu().detach().numpy())\n",
    "    \n",
    "    def append_test(self, loss: Tensor = None, preds: Tensor = None, targets: Tensor = None):\n",
    "        if loss is not None:\n",
    "            self.test_loss_buffer = np.append(self.test_loss_buffer, loss.cpu().detach().numpy())\n",
    "        if preds is not None and targets is not None:\n",
    "            self.test_labels_buffer = np.append(self.test_labels_buffer, targets)\n",
    "            self.test_preds_buffer = np.append(self.test_preds_buffer, preds.cpu().detach().numpy())\n",
    "\n",
    "    def plot(self):\n",
    "        # Train processing\n",
    "        if len(self.train_loss_buffer) > 0:\n",
    "            self.train_losses = np.append(self.train_losses, np.mean(self.train_loss_buffer))\n",
    "            self.train_loss_buffer = []\n",
    "        if len(self.train_preds_buffer) > 0 and len(self.train_labels_buffer) > 0:\n",
    "            train_acc = accuracy_score(self.train_labels_buffer, self.train_preds_buffer)\n",
    "            self.train_preds_buffer = []\n",
    "            self.train_labels_buffer = []\n",
    "            self.train_accuracies = np.append(self.train_accuracies, train_acc)\n",
    "        # Valid processing\n",
    "        if len(self.valid_loss_buffer) > 0:\n",
    "            self.valid_losses = np.append(self.valid_losses, np.mean(self.valid_loss_buffer))\n",
    "            self.valid_loss_buffer = []\n",
    "        if len(self.valid_preds_buffer) > 0 and len(self.valid_labels_buffer) > 0:\n",
    "            valid_acc = accuracy_score(self.valid_labels_buffer, self.valid_preds_buffer)\n",
    "            self.valid_labels_buffer = []\n",
    "            self.valid_preds_buffer = []\n",
    "            self.valid_accuracies = np.append(self.valid_accuracies, valid_acc)\n",
    "        # Test processing\n",
    "        if len(self.test_loss_buffer) > 0:\n",
    "            self.test_losses = np.append(self.test_losses, np.mean(self.test_loss_buffer))\n",
    "            self.test_loss_buffer = []\n",
    "        if len(self.test_preds_buffer) > 0 and len(self.test_labels_buffer) > 0:\n",
    "            test_acc = accuracy_score(self.test_labels_buffer, self.test_preds_buffer)\n",
    "            self.test_labels_buffer = []\n",
    "            self.test_preds_buffer = []\n",
    "            self.test_accuracies = np.append(self.test_accuracies, test_acc)\n",
    "        \n",
    "        # Display\n",
    "        clear_output(wait=True)\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(10, 5), squeeze=False)\n",
    "        ax = axs[0, 0]\n",
    "        ax.set_title('Loss')\n",
    "        ax.plot(self.train_losses, label = 'Training')\n",
    "        ax.plot(self.valid_losses, label = 'Validation')\n",
    "        ax.plot(self.test_losses, label = 'Test')\n",
    "        ax.legend()\n",
    "        \n",
    "        ax = axs[0, 1]\n",
    "        ax.set_title('Accuracy')\n",
    "        ax.plot(self.train_accuracies, label = 'Training')\n",
    "        ax.plot(self.valid_accuracies, label = 'Validation')\n",
    "        ax.plot(self.test_accuracies, label = 'Test')\n",
    "        ax.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        tmp_img = \"tmp_ae_out.png\"\n",
    "        plt.savefig(tmp_img)\n",
    "        plt.close(fig)\n",
    "        display(Image(filename=tmp_img))\n",
    "        \n",
    "        if len(self.train_losses) > 0 and len(self.valid_losses) > 0 and len(self.test_losses) > 0:\n",
    "            print(\"Training Loss: %.3f, Validation Loss: %.3f, Test Loss: %.3f\" %\n",
    "                  (self.train_losses[-1], self.valid_losses[-1], self.test_losses[-1]))\n",
    "        if len(self.train_accuracies) > 0 and len(self.valid_accuracies) > 0 and len(self.test_accuracies) > 0:\n",
    "            print(\"Training Accuracy: %.3f, Validation Accuracy: %.3f, Test Accuracy: %.3f\" %\n",
    "                  (self.train_accuracies[-1], self.valid_accuracies[-1], self.test_accuracies[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla FFNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FFNN IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a classification model\n",
    "class FFNN_Classifier(nn.Module):\n",
    "    def __init__(self, input_shape: torch.Size, num_classes: int, hidden_shape: [], dropout_prob:float = 0.5) -> None:\n",
    "        super(FFNN_Classifier, self).__init__()\n",
    "        \n",
    "        # Core params\n",
    "        self.input_shape = input_shape\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.epoch = 0\n",
    "        \n",
    "        # Model construction\n",
    "        model_shape = [self.observation_features]\n",
    "        model_shape.extend(hidden_shape)\n",
    "        model_shape.append(num_classes)\n",
    "        self.model = FF_NetworkConstructor(layers = model_shape,\n",
    "                                           pre_batchnorm = False,\n",
    "                                           hidden_batchnorm = True,\n",
    "                                           hidden_activation = nn.ReLU(),\n",
    "                                           dropout_prob = dropout_prob,\n",
    "                                           final_activation = nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x) -> Tensor:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FFNN TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFNN_Trainer:\n",
    "    def __init__(self,\n",
    "                 network: FFNN_Classifier,\n",
    "                 train_set: DataLoader,\n",
    "                 valid_set: DataLoader,\n",
    "                 test_set: DataLoader):\n",
    "        self.network = network\n",
    "        self.train_set = train_set\n",
    "        self.valid_set = valid_set\n",
    "        self.test_set = test_set\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.Adam(self.network.parameters(), lr=0.001)\n",
    "        self.plotter = Plotter()\n",
    "\n",
    "    def train(self):\n",
    "        self.network.train()\n",
    "        for images, labels in self.train_set:\n",
    "            self.optimizer.zero_grad()\n",
    "            classifications = self.network(images)\n",
    "            loss = self.criterion(classifications, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        self.network.epoch += 1\n",
    "    \n",
    "    def test(self):\n",
    "        self.network.eval()\n",
    "        \n",
    "        for images, labels in self.train_set:\n",
    "            classifications = self.network(images)\n",
    "            loss = self.criterion(classifications, labels)\n",
    "            self.plotter.append_train(loss, torch.argmax(classifications, 1), labels)\n",
    "        \n",
    "        for images, labels in self.valid_set:\n",
    "            classifications = self.network(images)\n",
    "            loss = self.criterion(classifications, labels)\n",
    "            self.plotter.append_valid(loss, torch.argmax(classifications, 1), labels)\n",
    "        \n",
    "        for images, labels in self.test_set:\n",
    "            classifications = self.network(images)\n",
    "            loss = self.criterion(classifications, labels)\n",
    "            self.plotter.append_test(loss, torch.argmax(classifications, 1), labels)\n",
    "        \n",
    "        self.plotter.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAE IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rF5c_hYM8v-o"
   },
   "outputs": [],
   "source": [
    "# Summarize values per sample\n",
    "def reduce(x: Tensor) -> Tensor:\n",
    "    return x.view(x.size(0), -1).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHWnmyLfrTBF"
   },
   "outputs": [],
   "source": [
    "# Implement VAE\n",
    "class M1_VAE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: torch.Size,\n",
    "                 latent_features: int,\n",
    "                 classes: int,\n",
    "                 hidden_layers_encoder: [], \n",
    "                 hidden_layers_decoder: [],\n",
    "                 hidden_layers_classifier: [],\n",
    "                 dropout_prob: float = 0.5) -> None:\n",
    "        super(M1_VAE, self).__init__()\n",
    "\n",
    "        # Core parameters\n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.classes = classes\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        # Having epochs here makes it possible to continue training, with correct epochs counting\n",
    "        self.epochs_vae = 0\n",
    "        self.epochs_class = 0\n",
    "        self.class_criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Constructing the encoder network\n",
    "        encoder_shape = [self.observation_features]\n",
    "        encoder_shape.extend(hidden_layers_encoder)\n",
    "        encoder_shape.append(self.latent_features * 2)\n",
    "        self.encoder = FF_NetworkConstructor(layers = encoder_shape,\n",
    "                                             pre_batchnorm = False,\n",
    "                                             hidden_batchnorm = True,\n",
    "                                             hidden_activation = nn.ReLU(),\n",
    "                                             dropout_prob = 0.0,\n",
    "                                             final_activation = None)\n",
    "\n",
    "        # Constructing the decoder network\n",
    "        decoder_shape = [self.latent_features]\n",
    "        decoder_shape.extend(hidden_layers_decoder)\n",
    "        decoder_shape.append(self.observation_features)\n",
    "        self.decoder = FF_NetworkConstructor(layers = decoder_shape,\n",
    "                                             pre_batchnorm = False,\n",
    "                                             hidden_batchnorm = True,\n",
    "                                             hidden_activation = nn.ReLU(),\n",
    "                                             dropout_prob = 0.0,\n",
    "                                             final_activation = None)\n",
    "        \n",
    "        # Constructing the classifier network\n",
    "        classifer_shape = [self.latent_features * 2]\n",
    "        classifer_shape.extend(hidden_layers_classifier)\n",
    "        classifer_shape.append(self.classes)\n",
    "        self.classifier = FF_NetworkConstructor(layers = classifer_shape,\n",
    "                                                pre_batchnorm = True,\n",
    "                                                hidden_batchnorm = True,\n",
    "                                                hidden_activation = nn.ReLU(),\n",
    "                                                dropout_prob = dropout_prob,\n",
    "                                                final_activation = nn.Sigmoid())\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.device = \"cuda:0\"\n",
    "            self.encoder.cuda()\n",
    "            self.decoder.cuda()\n",
    "            self.classifier.cuda()\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "            self.encoder.cpu()\n",
    "            self.decoder.cpu()\n",
    "            self.classifier.cpu()\n",
    "        \n",
    "    # Encode input into posterior distribution\n",
    "    def encode(self, x: Tensor) -> Distribution:\n",
    "        h_x = self.encoder(x)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "        result = ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        result.mu = result.mu.to(self.device)\n",
    "        result.sigma = result.sigma.to(self.device)\n",
    "        return result\n",
    "    \n",
    "    # Decode latent variables into reconstruction\n",
    "    def decode(self, z: Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(z)\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits=px_logits)\n",
    "    \n",
    "    # Get the prior distribution\n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        result = ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        result.mu = result.mu.to(self.device)\n",
    "        result.sigma = result.sigma.to(self.device)\n",
    "        return result\n",
    "    \n",
    "    def classify(self, z: Tensor) -> Tensor:\n",
    "        return self.classifier(z)\n",
    "    \n",
    "    # Sample from a provided distribution\n",
    "    def sample(self, distribution: ReparameterizedDiagonalGaussian) -> Tensor:\n",
    "        return distribution.rsample()\n",
    "    \n",
    "    # Compute the ELBO\n",
    "    def elbo(self, prior: Distribution, posterior: Distribution, reconstruction: Distribution, x: Tensor, z: Tensor) -> float:\n",
    "        tst = reconstruction.sample().to(self.device)\n",
    "        x = x.to(self.device)\n",
    "        z = z.to(self.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        log_px = reduce(reconstruction.log_prob(x))\n",
    "        log_pz = reduce(prior.log_prob(z))\n",
    "        log_qz = reduce(posterior.log_prob(z))\n",
    "        kl = log_qz - log_pz\n",
    "        elbo = log_px - kl\n",
    "        return elbo\n",
    "    \n",
    "    def class_loss(self, classifications: Tensor, labels: Tensor) -> float:\n",
    "        return self.class_criterion(classifications.to(self.device), labels.to(self.device))\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Dict[str, Any]:\n",
    "        # Figure out where model currently is located and update 'self.device'. \n",
    "        # Makes it possible to dynamically move model between cpu and cuda, after it has been initialized.\n",
    "        if next(self.parameters()).is_cuda:\n",
    "            self.device = \"cuda:0\"\n",
    "        else:\n",
    "            self.device = \"cpu\"\n",
    "        x = x.to(self.device)\n",
    "        x = x.view(x.size(0), -1) # flatten the input\n",
    "        qz = self.encode(x) # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        pz = self.prior(batch_size=x.size(0)) # define the prior p(z)\n",
    "        z = qz.rsample() # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        px = self.decode(z) # define the observation model p(x|z) = B(x | g(z))\n",
    "        #c = self.classify(torch.cat((qz.mu, qz.sigma), 1))\n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VAE TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE_Trainer:\n",
    "    def __init__(self,\n",
    "                 network:M1_VAE                 = None,\n",
    "                 train_labelled:DataLoader      = None,\n",
    "                 train_unlabelled:DataLoader    = None,\n",
    "                 valid_data:DataLoader          = None,\n",
    "                 test_data:DataLoader           = None):\n",
    "        self.model            = network          if network          != None else VAE_instance\n",
    "        self.train_labelled   = train_labelled   if train_labelled   != None else binarized_mnist_train_loader_labelled\n",
    "        self.train_unlabelled = train_unlabelled if train_unlabelled != None else binarized_mnist_train_loader_unlabelled\n",
    "        self.valid_data       = valid_data       if valid_data       != None else binarized_mnist_train_loader_validation\n",
    "        self.test_data        = test_data        if test_data        != None else binarized_mnist_test_loader\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.plotter = Plotter()\n",
    "    \n",
    "    def train_elbo(self):\n",
    "        self.model.train()\n",
    "        for images, labels in self.train_labelled:\n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(images)\n",
    "            loss = -self.model.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.train_unlabelled is not None:\n",
    "            for images, labels in self.train_unlabelled:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                loss = -self.model.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        self.model.epochs_vae += 1\n",
    "    \n",
    "    def train_classification(self):\n",
    "        if self.train_labelled is not None:\n",
    "            self.model.train()\n",
    "            for layer in self.model.encoder.children():\n",
    "                for param in layer.parameters():\n",
    "                    param.requires_grad = False\n",
    "            for images, labels in self.train_labelled:\n",
    "                outputs = self.model(images)\n",
    "                self.optimizer.zero_grad()\n",
    "                classifications = self.model.classify(torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1))\n",
    "                loss = self.model.class_loss(classifications, labels)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        self.model.epochs_class += 1\n",
    "    \n",
    "    def test_elbo(self):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        i = 0\n",
    "        for images, labels in self.train_labelled:\n",
    "            outputs = self.model(images)\n",
    "            loss = -self.model.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "            self.plotter.append_train(loss, None, None)\n",
    "        \n",
    "        if self.train_unlabelled is not None:\n",
    "            for images, labels in self.train_unlabelled:\n",
    "                outputs = self.model(images)\n",
    "                loss = -self.model.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "                self.plotter.append_train(loss, None, None)\n",
    "\n",
    "        for images, labels in self.valid_data:\n",
    "            outputs = self.model(images)\n",
    "            loss = -self.model.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "            self.plotter.append_valid(loss, None, None)\n",
    "\n",
    "        for images, labels in self.test_data:\n",
    "            outputs = self.model(images)\n",
    "            loss = -self.model.elbo(outputs['pz'], outputs['qz'], outputs['px'], images, outputs['z']).mean()\n",
    "            self.plotter.append_test(loss, None, None)\n",
    "\n",
    "        self.plotter.plot()\n",
    "        print(\"VAE Epochs: \", self.model.epochs_vae)\n",
    "        print(\"Classification Epochs: \", self.model.epochs_class)\n",
    "    \n",
    "    def test_classification(self, plot_loss: bool = False):\n",
    "        if self.train_labelled is not None:\n",
    "            self.model.eval()\n",
    "            losses = []\n",
    "            i = 0\n",
    "            for images, labels in self.train_labelled:\n",
    "                outputs = self.model(images)\n",
    "                classifications = self.model.classify(torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1))\n",
    "                preds = torch.argmax(classifications, 1)\n",
    "                if plot_loss:\n",
    "                    loss = self.model.class_loss(classifications, labels)\n",
    "                else:\n",
    "                    loss = None\n",
    "                self.plotter.append_train(loss, preds, labels)\n",
    "\n",
    "            for images, labels in self.valid_data:\n",
    "                outputs = self.model(images)\n",
    "                classifications = self.model.classify(torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1))\n",
    "                preds = torch.argmax(classifications, 1)\n",
    "                if plot_loss:\n",
    "                    loss = self.model.class_loss(classifications, labels)\n",
    "                else:\n",
    "                    loss = None\n",
    "                self.plotter.append_valid(loss, preds, labels)\n",
    "\n",
    "            for images, labels in self.test_data:\n",
    "                outputs = self.model(images)\n",
    "                classifications = self.model.classify(torch.cat((outputs['qz'].mu, outputs['qz'].sigma), 1))\n",
    "                preds = torch.argmax(classifications, 1)\n",
    "                if plot_loss:\n",
    "                    loss = self.model.class_loss(classifications, labels)\n",
    "                else:\n",
    "                    loss = None\n",
    "                self.plotter.append_test(loss, preds, labels)\n",
    "\n",
    "            self.plotter.plot()\n",
    "            print(\"VAE Epochs: \", self.model.epochs_vae)\n",
    "            print(\"Classification Epochs: \", self.model.epochs_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2 VAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPLEMENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_shape: torch.Size,\n",
    "                 latent_features: int,\n",
    "                 classes: int, \n",
    "                 hidden_layers_preclass: [], \n",
    "                 hidden_layers_postclass: [], \n",
    "                 hidden_layers_classification: [],\n",
    "                 hidden_layers_decoder: []):\n",
    "        super(M2_VAE, self).__init__()\n",
    "        \n",
    "        # Core params\n",
    "        self.input_shape = input_shape\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        self.register_buffer('classification_prior_params', torch.full(torch.Size([1, classes]), 1 / classes))\n",
    "        self.classes = classes\n",
    "        # Having epochs here makes it possible to continue training, with correct epochs counting\n",
    "        self.epochs = 0\n",
    "        \n",
    "        # Cuda enabling\n",
    "        if torch.cuda.is_available():\n",
    "            self.use_cuda = True\n",
    "            self.device = \"cuda:0\"\n",
    "        else:\n",
    "            self.use_cuda = False\n",
    "            self.device = \"cpu\"\n",
    "        \n",
    "        # Classifier construction\n",
    "        classifier_shape = [self.observation_features]\n",
    "        classifier_shape.extend(hidden_layers_classification)\n",
    "        classifier_shape.append(classes)\n",
    "        self.classifier = FF_NetworkConstructor(layers = classifier_shape,\n",
    "                                                pre_batchnorm = False,\n",
    "                                                hidden_batchnorm = True,\n",
    "                                                hidden_activation = nn.ReLU(),\n",
    "                                                dropout_prob = 0.5,\n",
    "                                                final_activation = None)\n",
    "        \n",
    "        # Pre-classification network construction\n",
    "        preclass_shape = [self.observation_features]\n",
    "        preclass_shape.extend(hidden_layers_preclass)\n",
    "        self.preclass_encoder = FF_NetworkConstructor(layers = preclass_shape,\n",
    "                                                      pre_batchnorm = False,\n",
    "                                                      hidden_batchnorm = True,\n",
    "                                                      hidden_activation = nn.ReLU(),\n",
    "                                                      dropout_prob = 0.5,\n",
    "                                                      final_activation = nn.ReLU())\n",
    "        \n",
    "        # Post-classification network construction\n",
    "        postclass_shape = [hidden_layers_preclass[-1] + classes]\n",
    "        postclass_shape.extend(hidden_layers_postclass)\n",
    "        postclass_shape.append(latent_features * 2)\n",
    "        self.postclass_encoder = FF_NetworkConstructor(layers = postclass_shape,\n",
    "                                                       pre_batchnorm = False,\n",
    "                                                       hidden_batchnorm = True,\n",
    "                                                       hidden_activation = nn.ReLU(),\n",
    "                                                       dropout_prob = 0.5,\n",
    "                                                       final_activation = None)\n",
    "        \n",
    "        # Decoder construction\n",
    "        decoder_shape = [latent_features + classes]\n",
    "        decoder_shape.extend(hidden_layers_decoder)\n",
    "        decoder_shape.append(self.observation_features)\n",
    "        self.decoder = FF_NetworkConstructor(layers = decoder_shape,\n",
    "                                             pre_batchnorm = False,\n",
    "                                             hidden_batchnorm = True,\n",
    "                                             hidden_activation = nn.ReLU(),\n",
    "                                             dropout_prob = 0.5,\n",
    "                                             final_activation = None)\n",
    "        \n",
    "        # Move networks to cuda if available\n",
    "        if self.use_cuda:\n",
    "            self.classifier.cuda()\n",
    "            self.preclass_encoder.cuda()\n",
    "            self.postclass_encoder.cuda()\n",
    "            self.decoder.cuda()\n",
    "\n",
    "    #def reset(self) -> None:\n",
    "    #    for layers in self.children():\n",
    "    #        for layer in layers:\n",
    "    #            if hasattr(layer, 'reset_parameters'):\n",
    "    #                layer.reset_parameters()\n",
    "    #    self.epochs = 0\n",
    "\n",
    "    def prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = local_prior_params.chunk(2, dim=-1)\n",
    "        result = ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "        result.mu = result.mu.to(self.device)\n",
    "        result.sigma = result.sigma.to(self.device)\n",
    "        return result\n",
    "    \n",
    "    def classification_prior(self, batch_size: int = 1) -> Distribution:\n",
    "        local_classification_prior_params = self.classification_prior_params.expand(batch_size, \n",
    "                                                                                    *self.classification_prior_params.shape[-1:])\n",
    "        result = Categorical(probs = local_classification_prior_params)\n",
    "        return result\n",
    "    \n",
    "    def classification_posterior(self, x: Tensor) -> Distribution:\n",
    "        result = self.classifier(x)\n",
    "        result = result.view(-1, self.classes)\n",
    "        result = Categorical(logits = result)\n",
    "        return result\n",
    "    \n",
    "    def classification_entropy(self, qy: Tensor) -> float:\n",
    "        qy = qy * torch.log(qy)\n",
    "        return -qy.sum(1)\n",
    "        \n",
    "    def encode(self, x: Tensor, y: Tensor = None) -> Tensor:\n",
    "        # Classify if no classification is provided\n",
    "        if y is None:\n",
    "            y = self.classifier(x)\n",
    "        # Encode input\n",
    "        result = self.preclass_encoder(x)\n",
    "        result = torch.cat((result, y), 1)\n",
    "        result = self.postclass_encoder(result)\n",
    "        mu, log_sigma =  result.chunk(2, dim=-1)\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def decode(self, z: Tensor, y: Tensor) -> Distribution:\n",
    "        px_logits = self.decoder(torch.cat((z, y), 1))\n",
    "        px_logits = px_logits.view(-1, *self.input_shape)\n",
    "        return Bernoulli(logits = px_logits)\n",
    "    \n",
    "    def onehot(self, y: int):\n",
    "        result = torch.zeros(y.shape[0], self.classes).to(self.device)\n",
    "        for i in range(len(y)):\n",
    "            result[i][y[i]] = 1\n",
    "        return result\n",
    "    \n",
    "    def loss(self,\n",
    "             px: Distribution, \n",
    "             py: Distribution, \n",
    "             pz: Distribution, \n",
    "             qy: Distribution, \n",
    "             qz: Distribution, \n",
    "             x: Tensor,\n",
    "             y: int, \n",
    "             z: Tensor,\n",
    "             alpha: float,\n",
    "             debug: bool = False) -> float:\n",
    "        x = x.to(self.device)\n",
    "        z = z.to(self.device)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        py_logprob = py.logits.to(self.device)\n",
    "        \n",
    "        # If labels are not provided, sample from classification posterior\n",
    "        if y is None:\n",
    "            x2 = x.repeat(10,1)\n",
    "            y2 = torch.Tensor(0)\n",
    "            for i in range(10):\n",
    "                y2 = torch.cat( (y2, torch.Tensor([i]).expand(x.shape[0])))\n",
    "            y2 = y2.to(self.device)\n",
    "            outputs = self.forward(x2, y2)\n",
    "            px_logprob = outputs['px'].log_prob(x2.view(10*x.shape[0],-1)).sum(dim=1).view(-1,10)\n",
    "            qz_logprob = outputs['qz'].log_prob(outputs['z']).sum(dim=1).view(-1, 10)\n",
    "            pz_logprob = outputs['pz'].log_prob(outputs['z']).sum(dim=1).view(-1, 10)\n",
    "            L = -(px_logprob + py_logprob + pz_logprob - qz_logprob)\n",
    "            U = -(torch.mul(qy.probs, -L).sum(1) + self.classification_entropy(qy.probs))\n",
    "            J = U\n",
    "            return J\n",
    "        else:\n",
    "            y = y.to(self.device)\n",
    "            y = y.view(-1, 1)\n",
    "            px_logprob = px.log_prob(x).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            qz_logprob = qz.log_prob(z).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            pz_logprob = pz.log_prob(z).sum(dim = 1).view(-1, 1).repeat(1, 10)\n",
    "            L = -(px_logprob + py_logprob + pz_logprob - qz_logprob)\n",
    "            J = L.gather(1, y)\n",
    "            J_alpha = J - (alpha * qy.logits.gather(1, y))\n",
    "            return J_alpha\n",
    "    \n",
    "    def forward(self, x: Tensor, y: int = None, debug: bool = False) -> Dict[str, Any]:\n",
    "        x = x.to(self.device) # Move to cuda if applicable\n",
    "        x = x.view(x.size(0), -1) # Flatten image input\n",
    "        qy = self.classification_posterior(x) # Classification posterior q(y|x)\n",
    "        py = self.classification_prior(batch_size = x.size(0)) # Classification prior p(y)\n",
    "        pz = self.prior(batch_size=x.size(0)) # Prior p(z)\n",
    "        if y is None: # If labels are not provided, sample from classification posterior\n",
    "            try:\n",
    "                y = qy.sample()\n",
    "            except:\n",
    "                print(self.classifier(x))\n",
    "                raise Exception(\"QY sample error\")\n",
    "        \n",
    "        y = y.to(self.device)\n",
    "        y = y.int()\n",
    "        y = self.onehot(y)\n",
    "        qz = self.encode(x, y) # Approximate posterior q(z|x, y)\n",
    "        z = qz.rsample() # Sample the posterior\n",
    "        px = self.decode(z, y) # Reconstruction p(x|z, y) = B(x | g(z, y))\n",
    "        \n",
    "        return {'px': px, 'py': py, 'pz': pz, 'qy': qy, 'qz': qz, 'z': z}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINER**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class M2_VAE_Trainer:\n",
    "    def __init__(self,\n",
    "                 network:M2_VAE              = None,\n",
    "                 train_labelled:DataLoader   = None,\n",
    "                 train_unlabelled:DataLoader = None,\n",
    "                 valid:DataLoader            = None,\n",
    "                 test:DataLoader             = None,\n",
    "                 labelled_ratio:int          = 1,\n",
    "                 alpha:float                 = 0.1,\n",
    "                 verbose:int                 = 0):\n",
    "        self.model            = network          if network          != None else M2_instance\n",
    "        self.train_labelled   = train_labelled   if train_labelled   != None else binarized_mnist_train_loader_labelled\n",
    "        self.train_unlabelled = train_unlabelled if train_unlabelled != None else binarized_mnist_train_loader_unlabelled\n",
    "        self.valid_data       = valid            if valid            != None else binarized_mnist_train_loader_validation\n",
    "        self.test_data        = test             if test             != None else binarized_mnist_test_loader\n",
    "        self.alpha = alpha\n",
    "        self.training_data = defaultdict(list)\n",
    "        self.validation_data = defaultdict(list)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
    "        self.labelled_ratio = labelled_ratio\n",
    "        self.plotter = Plotter()\n",
    "    \n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "        if self.train_unlabelled is not None:\n",
    "            labelled_iter = iter(self.train_unlabelled)\n",
    "            for images, labels in self.train_unlabelled:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images, None)\n",
    "                loss = self.model.loss(outputs['px'], \n",
    "                                       outputs['py'], \n",
    "                                       outputs['pz'], \n",
    "                                       outputs['qy'], \n",
    "                                       outputs['qz'],\n",
    "                                       images, \n",
    "                                       None,\n",
    "                                       outputs['z'],\n",
    "                                       self.alpha).mean()\n",
    "                for i in range(self.labelled_ratio):\n",
    "                    try:\n",
    "                        img_lbl, lbl_lbl = next(labelled_iter)\n",
    "                    except StopIteration:\n",
    "                        labelled_iter = iter(self.train_unlabelled)\n",
    "                        img_lbl, lbl_lbl = next(labelled_iter)\n",
    "                    outputs = self.model(img_lbl, lbl_lbl)\n",
    "                    loss += self.model.loss(outputs['px'], \n",
    "                                            outputs['py'], \n",
    "                                            outputs['pz'], \n",
    "                                            outputs['qy'], \n",
    "                                            outputs['qz'],\n",
    "                                            img_lbl, \n",
    "                                            lbl_lbl,\n",
    "                                            outputs['z'],\n",
    "                                            self.alpha).mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        else:\n",
    "            for images, labels in self.train_labelled:\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(images, labels)\n",
    "                loss = self.model.loss(outputs['px'], \n",
    "                                       outputs['py'], \n",
    "                                       outputs['pz'], \n",
    "                                       outputs['qy'], \n",
    "                                       outputs['qz'],\n",
    "                                       images, \n",
    "                                       labels,\n",
    "                                       outputs['z'],\n",
    "                                       self.alpha).mean()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "        self.model.epochs += 1\n",
    "    \n",
    "    def test(self):\n",
    "        self.model.eval()\n",
    "        losses = []\n",
    "        i = 0\n",
    "        epoch_data = defaultdict(list)\n",
    "        for images, labels in self.train_labelled:\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha).mean()\n",
    "            classifications = self.model.classifier(images.view(-1,28*28).to(self.model.device))\n",
    "            preds = torch.argmax(classifications,1)\n",
    "            self.plotter.append_train(loss, preds, labels)\n",
    "\n",
    "        for images, labels in self.valid_data:\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha).mean()\n",
    "            classifications = self.model.classifier(images.view(-1,28*28).to(self.model.device))\n",
    "            preds = torch.argmax(classifications,1)\n",
    "            self.plotter.append_valid(loss, preds, labels)\n",
    "\n",
    "        for images, labels in self.test_data:\n",
    "            outputs = self.model(images, labels)\n",
    "            loss = self.model.loss(outputs['px'], \n",
    "                                   outputs['py'], \n",
    "                                   outputs['pz'], \n",
    "                                   outputs['qy'], \n",
    "                                   outputs['qz'],\n",
    "                                   images, \n",
    "                                   labels,\n",
    "                                   outputs['z'],\n",
    "                                   self.alpha).mean()\n",
    "            classifications = self.model.classifier(images.view(-1,28*28).to(self.model.device))\n",
    "            preds = torch.argmax(classifications,1)\n",
    "            self.plotter.append_test(loss, preds, labels)\n",
    "\n",
    "        self.plotter.plot()\n",
    "        print(\"Epochs: \", self.model.epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple FF classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FF 100 lbls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "ffnn = FFNN_Classifier(sample.flatten().shape, 10, [500, 250], dropout_prob=0.0)\n",
    "loader_setup(labelled_size=100)\n",
    "trainer = FFNN_Trainer(ffnn,\n",
    "                       binarized_mnist_train_loader_labelled,\n",
    "                       binarized_mnist_train_loader_validation,\n",
    "                       binarized_mnist_test_loader)\n",
    "epochs = 50\n",
    "fn = \"ff_100_labelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    ffnn.load_state_dict(torch.load(fn))\n",
    "    trainer.test()\n",
    "    print(\"Model loaded from '%s'\" % fn)\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(ffnn.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FF 1000 lbls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "ffnn = FFNN_Classifier(sample.flatten().shape, 10, [500, 250], dropout_prob=0.1)\n",
    "loader_setup(labelled_size=1000)\n",
    "trainer = FFNN_Trainer(ffnn,\n",
    "                       binarized_mnist_train_loader_labelled,\n",
    "                       binarized_mnist_train_loader_validation,\n",
    "                       binarized_mnist_test_loader)\n",
    "epochs = 50\n",
    "fn = \"ff_1k_labelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    ffnn.load_state_dict(torch.load(fn))\n",
    "    trainer.test()\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(ffnn.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FF 10k lbls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "ffnn = FFNN_Classifier(sample.flatten().shape, 10, [500, 250], dropout_prob=0.3)\n",
    "loader_setup(labelled_size=10000)\n",
    "trainer = FFNN_Trainer(ffnn,\n",
    "                       binarized_mnist_train_loader_labelled,\n",
    "                       binarized_mnist_train_loader_validation,\n",
    "                       binarized_mnist_test_loader)\n",
    "epochs = 50\n",
    "fn = \"ff_10k_labelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    ffnn.load_state_dict(torch.load(fn))\n",
    "    trainer.test()\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(ffnn.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FF 50k lbls**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "ffnn = FFNN_Classifier(sample.flatten().shape, 10, [500, 250], dropout_prob=0.5)\n",
    "loader_setup(labelled_size=50000, validation_size=10000)\n",
    "trainer = FFNN_Trainer(ffnn,\n",
    "                       binarized_mnist_train_loader_labelled,\n",
    "                       binarized_mnist_train_loader_validation,\n",
    "                       binarized_mnist_test_loader)\n",
    "epochs = 50\n",
    "fn = \"ff_50k_labelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    ffnn.load_state_dict(torch.load(fn))\n",
    "    trainer.test()\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(ffnn.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard VAE (M1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M1 100/0 LABELLED/UNLABELLED OBSERVATIONS**\n",
    "\n",
    "For 0 unlabelled data, we're passing the same set of 100 observations as labelled and unlabelled training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate a VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(0)[0]\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "# Initialize trainer\n",
    "loader_setup(labelled_size = 100, unlabelled_size = 0, validation_size = 10000)\n",
    "trainer = VAE_Trainer(VAE_instance,\n",
    "                      binarized_mnist_train_loader_labelled,\n",
    "                      binarized_mnist_train_loader_labelled, # Pass the labelled pool as unlabelled set for core VAE training\n",
    "                      binarized_mnist_train_loader_validation,\n",
    "                      binarized_mnist_test_loader)\n",
    "# Train the VAE\n",
    "epochs = 100\n",
    "fn = \"m1_class_100_labelled_0_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded VAE_instance model from %s\" % fn)\n",
    "else:\n",
    "    for i in range(epochs):\n",
    "        trainer.train_elbo()\n",
    "        trainer.test_elbo()\n",
    "    for i in range(epochs):\n",
    "        trainer.train_classification()\n",
    "        trainer.test_classification(False)\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M1 100/100 LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate a VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(0)[0]\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "# Initialize trainer\n",
    "loader_setup(labelled_size = 100, unlabelled_size = 100, validation_size = 10000)\n",
    "trainer = VAE_Trainer(VAE_instance,\n",
    "                      binarized_mnist_train_loader_labelled,\n",
    "                      binarized_mnist_train_loader_unlabelled,\n",
    "                      binarized_mnist_train_loader_validation,\n",
    "                      binarized_mnist_test_loader)\n",
    "# Train the VAE\n",
    "epochs = 100\n",
    "fn = \"m1_class_100_labelled_100_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded VAE_instance model from %s\" % fn)\n",
    "else:\n",
    "    for i in range(epochs):\n",
    "        trainer.train_elbo()\n",
    "        trainer.test_elbo()\n",
    "    for i in range(epochs):\n",
    "        trainer.train_classification()\n",
    "        trainer.test_classification(False)\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100/1K LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate a VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(0)[0]\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "# Initialize trainer\n",
    "loader_setup(labelled_size = 100, unlabelled_size = 1000, validation_size = 10000)\n",
    "trainer = VAE_Trainer(VAE_instance,\n",
    "                      binarized_mnist_train_loader_labelled,\n",
    "                      binarized_mnist_train_loader_unlabelled,\n",
    "                      binarized_mnist_train_loader_validation,\n",
    "                      binarized_mnist_test_loader)\n",
    "# Train the VAE\n",
    "epochs = 100\n",
    "fn = \"m1_class_100_labelled_1k_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded VAE_instance model from %s\" % fn)\n",
    "else:\n",
    "    for i in range(epochs):\n",
    "        trainer.train_elbo()\n",
    "        trainer.test_elbo()\n",
    "    for i in range(epochs):\n",
    "        trainer.train_classification()\n",
    "        trainer.test_classification(False)\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100/10K LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate a VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(0)[0]\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "# Initialize trainer\n",
    "loader_setup(labelled_size = 100, unlabelled_size = 10000, validation_size = 10000)\n",
    "trainer = VAE_Trainer(VAE_instance,\n",
    "                      binarized_mnist_train_loader_labelled,\n",
    "                      binarized_mnist_train_loader_unlabelled,\n",
    "                      binarized_mnist_train_loader_validation,\n",
    "                      binarized_mnist_test_loader)\n",
    "# Train the VAE\n",
    "epochs = 100\n",
    "fn = \"m1_class_100_labelled_10k_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded VAE_instance model from %s\" % fn)\n",
    "else:\n",
    "    for i in range(epochs):\n",
    "        trainer.train_elbo()\n",
    "        trainer.test_elbo()\n",
    "    for i in range(epochs):\n",
    "        trainer.train_classification()\n",
    "        trainer.test_classification(False)\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M1 VAE only training**\n",
    "\n",
    "As we start exploring the potential of adding labelled observations to a latent space trained on 40k unlabelled observations, we just train a core VAE on the 40k observations and save it without doing any classification training. We then load that model and run classification trainings on it (model with trained classifier saved seperately).\n",
    "\n",
    "In subsequent classification training, we omit unlabelled training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "loader_setup(labelled_size=0, unlabelled_size = 50000, validation_size = 10000, test_size=10000)\n",
    "trainer = VAE_Trainer()\n",
    "epochs_vae = 200\n",
    "fn = \"m1_class_50_lspc.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded VAE_instance model from %s\" % fn)\n",
    "else:\n",
    "    for i in range(epochs_vae):\n",
    "        trainer.train_elbo()\n",
    "        trainer.test_elbo()\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M1 100/40k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "\n",
    "fn = \"m1_class_100_labelled_40k_50_lspc.pt\"\n",
    "\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    loader_setup(labelled_size=100, unlabelled_size=0, validation_size = 100)\n",
    "    trainer = VAE_Trainer()\n",
    "    trainer.test_classification()\n",
    "else:\n",
    "    fn_base = \"m1_class_50_lspc.pt\"\n",
    "    VAE_instance.load_state_dict(torch.load(fn_base))\n",
    "    loader_setup(labelled_size=100, unlabelled_size=0, validation_size = 100)\n",
    "    trainer = VAE_Trainer()\n",
    "    #for layer in VAE_instance.classifier.children():\n",
    "    #    if hasattr(layer, 'reset_parameters'):\n",
    "    #        layer.reset_parameters()\n",
    "    trainer.test_classification()\n",
    "    epochs_class = 70\n",
    "    for i in range(epochs_class):\n",
    "        trainer.train_classification()\n",
    "        trainer.test_classification()\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M1 1000/40k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "\n",
    "fn = \"m1_class_1k_labelled_40k_50_lspc.pt\"\n",
    "\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    loader_setup(labelled_size=1000, unlabelled_size=0, validation_size = 10000)\n",
    "    trainer = VAE_Trainer()\n",
    "    trainer.test_classification()\n",
    "else:\n",
    "    fn_base = \"m1_class_50_lspc.pt\"\n",
    "    VAE_instance.load_state_dict(torch.load(fn_base))\n",
    "    loader_setup(labelled_size=1000, unlabelled_size=0, validation_size = 10000)\n",
    "    trainer = VAE_Trainer()\n",
    "    #for layer in VAE_instance.classifier.children():\n",
    "    #    if hasattr(layer, 'reset_parameters'):\n",
    "    #        layer.reset_parameters()\n",
    "    trainer.test_classification()\n",
    "    epochs_class = 100\n",
    "    for i in range(epochs_class):\n",
    "        trainer.train_classification()\n",
    "        trainer.test_classification()\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M1 10k/40k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "\n",
    "fn = \"m1_class_10k_labelled_40k_50_lspc.pt\"\n",
    "\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    loader_setup(labelled_size=10000, unlabelled_size=0, validation_size = 100)\n",
    "    trainer = VAE_Trainer()\n",
    "    trainer.test_classification()\n",
    "else:\n",
    "    fn_base = \"m1_class_50_lspc.pt\"\n",
    "    VAE_instance.load_state_dict(torch.load(fn_base))\n",
    "    loader_setup(labelled_size=10000, unlabelled_size=0, validation_size = 100)\n",
    "    trainer = VAE_Trainer()\n",
    "    #for layer in VAE_instance.classifier.children():\n",
    "    #    if hasattr(layer, 'reset_parameters'):\n",
    "    #        layer.reset_parameters()\n",
    "    trainer.test_classification()\n",
    "    epochs_class = 100\n",
    "    for i in range(epochs_class):\n",
    "        trainer.train_classification()\n",
    "        trainer.test_classification()\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M1 50k/40k**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "\n",
    "fn = \"m1_class_50k_labelled_40k_50_lspc.pt\"\n",
    "\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    loader_setup(labelled_size=50000, unlabelled_size=0, validation_size = 100)\n",
    "    trainer = VAE_Trainer()\n",
    "    trainer.test_classification()\n",
    "else:\n",
    "    fn_base = \"m1_class_50_lspc.pt\"\n",
    "    VAE_instance.load_state_dict(torch.load(fn_base))\n",
    "    loader_setup(labelled_size=50000, unlabelled_size=0, validation_size = 100)\n",
    "    trainer = VAE_Trainer()\n",
    "    #for layer in VAE_instance.classifier.children():\n",
    "    #    if hasattr(layer, 'reset_parameters'):\n",
    "    #        layer.reset_parameters()\n",
    "    trainer.test_classification()\n",
    "    epochs_class = 15\n",
    "    for i in range(epochs_class):\n",
    "        trainer.train_classification()\n",
    "        trainer.test_classification()\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**M1 5 DIMENSIONAL LATENT SPACE**\n",
    "\n",
    "This model is trained just to have a VAE model with lower dimensionality for comparison of latent space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "VAE_instance = M1_VAE(sample.flatten().shape,\n",
    "                      50,\n",
    "                      10,\n",
    "                      [450, 250, 100],\n",
    "                      [128, 256, 512],\n",
    "                      [100, 80],\n",
    "                      dropout_prob = 0.0)\n",
    "loader_setup(labelled_size=0, unlabelled_size = 50000, validation_size = 10000, test_size=10000)\n",
    "trainer = VAE_Trainer()\n",
    "epochs_vae = 200\n",
    "fn = \"m1_class_5_lspc.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    VAE_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded VAE_instance model from %s\" % fn)\n",
    "else:\n",
    "    for i in range(epochs_vae):\n",
    "        trainer.train_elbo()\n",
    "        trainer.test_elbo()\n",
    "    torch.save(VAE_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M1 - Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LATENT TRAVERSAL**\n",
    "\n",
    "This is generally more \"fun\" on M1 models with fewer latent dimensions, where single planes are more likely to contain multiple clearly defined digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent space traversal\n",
    "x_dimension = 0\n",
    "y_dimension = 1\n",
    "traversal_speed = 1\n",
    "\n",
    "VAE_instance.eval()\n",
    "fig, axs = plt.subplots(11, 11, figsize=(11, 11), squeeze=False)\n",
    "z = torch.zeros(11, VAE_instance.latent_features).cuda() # Plotting from 11 points in 5-dimensional latent space\n",
    "for i in range(11):\n",
    "    z[i, x_dimension] = (i-5) * traversal_speed\n",
    "for i in range(11):\n",
    "    for j in range(11):\n",
    "        z[j, y_dimension] = (i-5) * traversal_speed\n",
    "    for j in range(11):\n",
    "        image = VAE_instance.decode(z[j].reshape(1, -1)).sample().view(28,28).cpu()\n",
    "        axs[i, j].imshow(image, cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LATENT VARIABLE DISTRIBUTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_setup(labelled_size = 50000)\n",
    "VAE_instance.eval()\n",
    "mus = []\n",
    "sigmas = []\n",
    "for images, labels in binarized_mnist_train_loader_labelled:\n",
    "    outputs = VAE_instance(images)\n",
    "    tmp = outputs['qz'].mu.cpu().detach().numpy()\n",
    "    mus.extend(tmp)\n",
    "    tmp = outputs['qz'].sigma.cpu().detach().numpy()\n",
    "    sigmas.extend(tmp)\n",
    "for images, labels in binarized_mnist_train_loader_validation:\n",
    "    outputs = VAE_instance(images)\n",
    "    tmp = outputs['qz'].mu.cpu().detach().numpy()\n",
    "    mus.extend(tmp)\n",
    "    tmp = outputs['qz'].sigma.cpu().detach().numpy()\n",
    "    sigmas.extend(tmp)\n",
    "for images, labels in binarized_mnist_test_loader:\n",
    "    outputs = VAE_instance(images)\n",
    "    tmp = outputs['qz'].mu.cpu().detach().numpy()\n",
    "    mus.extend(tmp)\n",
    "    tmp = outputs['qz'].sigma.cpu().detach().numpy()\n",
    "    sigmas.extend(tmp)\n",
    "\n",
    "mus = np.array(mus).reshape(-1, 1).squeeze()\n",
    "sigmas = np.array(sigmas).reshape(-1, 1).squeeze()\n",
    "\n",
    "n, bins, patches = plt.hist(mus, 100)\n",
    "plt.xlabel('Mu')\n",
    "plt.ylabel('Occurances')\n",
    "plt.title('Mu Occurances')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "n, bins, patches = plt.hist(sigmas, 100)\n",
    "plt.xlabel('Sigma')\n",
    "plt.ylabel('Occurances')\n",
    "plt.title('Sigma Occurances')\n",
    "plt.grid(True)\n",
    "plt.xlim(0, 0.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2 - Setup and Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100/0 LABELLED_UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "M2_instance = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [500, 250], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "# Instantiate trainer\n",
    "loader_setup(labelled_size=100, unlabelled_size=0)\n",
    "trainer = M2_VAE_Trainer(M2_instance,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.5)\n",
    "# Training\n",
    "epochs = 100\n",
    "fn = \"m2_class_100_labelled_0_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    M2_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(M2_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100/100 LABELLED_UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "M2_instance = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [500, 250], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "# Instantiate trainer\n",
    "loader_setup(labelled_size=100, unlabelled_size=100)\n",
    "trainer = M2_VAE_Trainer(M2_instance,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.5)\n",
    "# Training\n",
    "epochs = 100\n",
    "fn = \"m2_class_100_labelled_100_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    M2_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(M2_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100/1K LABELLED_UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "M2_instance = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [500, 250], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "# Instantiate trainer\n",
    "loader_setup(labelled_size=100, unlabelled_size=1000)\n",
    "trainer = M2_VAE_Trainer(M2_instance,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.5)\n",
    "# Training\n",
    "epochs = 100\n",
    "fn = \"m2_class_100_labelled_1k_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    M2_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(M2_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100/10K LABELLED_UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "M2_instance = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [500, 250], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "# Instantiate trainer\n",
    "loader_setup(labelled_size=100, unlabelled_size=10000)\n",
    "trainer = M2_VAE_Trainer(M2_instance,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.5)\n",
    "# Training\n",
    "epochs = 20\n",
    "fn = \"m2_class_100_labelled_10k_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    M2_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(M2_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**100/40K LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "M2_instance = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [500, 250], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "# Instantiate trainer\n",
    "loader_setup(labelled_size=100, unlabelled_size=40000)\n",
    "trainer = M2_VAE_Trainer(M2_instance,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.5)\n",
    "# Training\n",
    "epochs = 20\n",
    "fn = \"m2_class_100_labelled_40k_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    M2_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(M2_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1K/40K LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "M2_instance = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [500, 250], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "# Instantiate trainer\n",
    "loader_setup(labelled_size=1000, unlabelled_size=40000)\n",
    "trainer = M2_VAE_Trainer(M2_instance,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.5)\n",
    "# Training\n",
    "epochs = 20\n",
    "fn = \"m2_class_1k_labelled_40k_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    M2_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(M2_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10K/40K LABELLED/UNLABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "M2_instance = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [500, 250], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "# Instantiate trainer\n",
    "loader_setup(labelled_size=10000, unlabelled_size=40000)\n",
    "trainer = M2_VAE_Trainer(M2_instance,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.5)\n",
    "# Training\n",
    "epochs = 20\n",
    "fn = \"m2_class_10k_labelled_40k_unlabelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    M2_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(M2_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**50K LABELLED OBSERVATIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Instantiate VAE\n",
    "sample = binarized_mnist_train_data.__getitem__(22)[0]\n",
    "M2_instance = M2_VAE(sample.flatten().shape, # Input shape\n",
    "                5, # Latent features\n",
    "                10, # Classes\n",
    "                [200], # Network dimensions for encoder before adding classifications\n",
    "                [200], # Network dimensions for encoder after adding classification\n",
    "                [500, 250], # Network dimensions for classification network\n",
    "                [200, 400, 600]) # Network dimensions for decoder\n",
    "# Instantiate trainer\n",
    "loader_setup(labelled_size=50000)\n",
    "trainer = M2_VAE_Trainer(M2_instance,\n",
    "                         binarized_mnist_train_loader_labelled,\n",
    "                         binarized_mnist_train_loader_unlabelled,\n",
    "                         binarized_mnist_train_loader_validation,\n",
    "                         binarized_mnist_test_loader,\n",
    "                         10,\n",
    "                         0.5)\n",
    "# Training\n",
    "epochs = 20\n",
    "fn = \"m2_class_50k_labelled.pt\"\n",
    "if use_saved_models and os.path.isfile(fn):\n",
    "    M2_instance.load_state_dict(torch.load(fn))\n",
    "    print(\"Loaded model from %s\" % fn)\n",
    "    trainer.test()\n",
    "else:\n",
    "    trainer.test()\n",
    "    for i in range(epochs):\n",
    "        trainer.train()\n",
    "        trainer.test()\n",
    "    torch.save(M2_instance.state_dict(), fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M2 Generative Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run any M2 loading/training cell above to ensure that M2_instance references the desired model. Then run the cells below to generate visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STYLE TRANSFER - LATENT REPRESENTATION ENCODED FROM OBSERVATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style Transfer\n",
    "M2_instance.eval()\n",
    "a = random.choices(binarized_mnist_train_data,k=10)\n",
    "b = [x[0] for x in a]\n",
    "img = torch.stack(b)\n",
    "b = [x[1] for x in a]\n",
    "lbl = torch.Tensor(b)\n",
    "fig, axs = plt.subplots(10, 11, figsize=(10, 10), squeeze=False)\n",
    "\n",
    "outputs = M2_instance(img, lbl)\n",
    "z = outputs['z']\n",
    "\n",
    "for i in range(len(img)):\n",
    "    axs[i, 0].imshow(img[i], cmap='gray')\n",
    "    axs[i, 0].axis('off')\n",
    "    for j in range(10):\n",
    "        image = M2_instance.decode(z[i].reshape(1, -1), M2_instance.onehot(torch.Tensor([j]).int())).sample().view(28,28).cpu()\n",
    "        axs[i, j + 1].imshow(image, cmap='gray')\n",
    "        axs[i, j + 1].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LATENT TRAVERSAL - SPECIFIC DIGITS, TRAVERSING MULTIPLE AXIS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent space traversal\n",
    "x_dimension = 0\n",
    "y_dimension = 1\n",
    "traversal_speed = 0.5\n",
    "digit = 4\n",
    "\n",
    "M2_instance.eval()\n",
    "fig, axs = plt.subplots(11, 11, figsize=(11, 11), squeeze=False)\n",
    "z = torch.zeros(11, 5).cuda() # Plotting from 11 points in 5-dimensional latent space\n",
    "for i in range(11):\n",
    "    z[i, x_dimension] = (i-5) * traversal_speed\n",
    "for i in range(11):\n",
    "    for j in range(11):\n",
    "        z[j, y_dimension] = (i-5) * traversal_speed\n",
    "    for j in range(11):\n",
    "        image = M2_instance.decode(z[j].reshape(1, -1), M2_instance.onehot(torch.Tensor([digit]).int())).sample().view(28,28).cpu()\n",
    "        axs[i, j].imshow(image, cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LATENT TRAVERSAL - ALL DIGITS ALONG DIAGONAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent space traversal\n",
    "traversal_speed = 0.5\n",
    "\n",
    "M2_instance.eval()\n",
    "fig, axs = plt.subplots(10, 10, figsize=(10, 10), squeeze=False)\n",
    "outputs = M2_instance(img, lbl)\n",
    "z = torch.Tensor(11, 5).cuda() # Plotting from 11 points in 5-dimensional latent space\n",
    "for i in range(11):\n",
    "    for j in range(5):\n",
    "        z[i, j] = (i-5) * traversal_speed\n",
    "for i in range(10):\n",
    "    axs[i, 0].axis('off')\n",
    "    for j in range(10):\n",
    "        image = M2_instance.decode(z[i].reshape(1, -1), M2_instance.onehot(torch.Tensor([j]).int())).sample().view(28,28).cpu()\n",
    "        axs[i, j].imshow(image, cmap='gray')\n",
    "        axs[i, j].axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PERFORMANCE - PLAIN FF VS SEMISUPERVISED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['0', '100', '1000', '10000', '40000']\n",
    "ff_accuracies = [72.8, 72.8, 72.8, 72.8, 72.8]\n",
    "m1_accuracies = [63.5, 70.0, 75.6, 77.2, 85.0]\n",
    "m2_accuracies = [75.6, 64.3, 86.9, 90.3, 94.3]\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.20  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar(x - width, ff_accuracies, width, label='FF')\n",
    "rects2 = ax.bar(x, m1_accuracies, width, label='M1 VAE')\n",
    "rects3 = ax.bar(x + width, m2_accuracies, width, label='M2 VAE')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Unlabelled Observations')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend(loc='lower right')\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "VAE Eksamen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
